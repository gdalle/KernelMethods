{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-13T11:58:57.846700Z",
     "start_time": "2019-02-13T11:58:56.876613Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-13T11:58:57.873845Z",
     "start_time": "2019-02-13T11:58:57.850955Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/Xtr0.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-13T11:58:57.892666Z",
     "start_time": "2019-02-13T11:58:57.876106Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>GGAGAATCATTTGAACCCGGGAGGTGGAGGTTGCCGTGAGCTGAGA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ACCCTGCCTACACCGCGGCGGGGACAGGTGGAGGTTTCAACCCCTG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>TGCAAATCTGTAAGCATTTCTCAGGCAATGAATTATGTCAACACAA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>GCGGGACGTGGGCGTCGAGGGTAAGGATATCTGCAGAAGTACTGTC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>GGAGAATAGCATGTATCCGAGAGGTGGAGCTGGCAGTGAGCCGAGA...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id                                                seq\n",
       "0   0  GGAGAATCATTTGAACCCGGGAGGTGGAGGTTGCCGTGAGCTGAGA...\n",
       "1   1  ACCCTGCCTACACCGCGGCGGGGACAGGTGGAGGTTTCAACCCCTG...\n",
       "2   2  TGCAAATCTGTAAGCATTTCTCAGGCAATGAATTATGTCAACACAA...\n",
       "3   3  GCGGGACGTGGGCGTCGAGGGTAAGGATATCTGCAGAAGTACTGTC...\n",
       "4   4  GGAGAATAGCATGTATCCGAGAGGTGGAGCTGGCAGTGAGCCGAGA..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All sequences is this set have length 101."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-13T11:58:57.901544Z",
     "start_time": "2019-02-13T11:58:57.895814Z"
    }
   },
   "outputs": [],
   "source": [
    "letters = 'ATCG'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-13T11:58:57.907090Z",
     "start_time": "2019-02-13T11:58:57.904370Z"
    }
   },
   "outputs": [],
   "source": [
    "length = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-13T11:58:57.918703Z",
     "start_time": "2019-02-13T11:58:57.910790Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_voc(letters, length):\n",
    "    vocl = [''.join(x) for x in itertools.product(letters, repeat=length)]\n",
    "    voc = {}\n",
    "    i = 0\n",
    "    for v in vocl:\n",
    "        voc[v] = i\n",
    "        i+=1\n",
    "    return voc\n",
    "voc = build_voc(letters, length)\n",
    "# print(voc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\Phi_u(x)$ is the number of occurrences of u in x (without gaps) : *spectrum kernel* (Leslie et al., 2002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-13T11:58:57.926063Z",
     "start_time": "2019-02-13T11:58:57.921356Z"
    }
   },
   "outputs": [],
   "source": [
    "def substrings(x, length):\n",
    "    n = len(x)\n",
    "    sub = []\n",
    "    assert n>=length, 'seq too small'\n",
    "    for i in range(n-length+1):\n",
    "        curr = x[i:i+length]\n",
    "        sub.append(curr)\n",
    "    return sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-13T11:58:57.933923Z",
     "start_time": "2019-02-13T11:58:57.927943Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GGAGAA', 'GAGAAT', 'AGAATC', 'GAATCA', 'AATCAT', 'ATCATT', 'TCATTT', 'CATTTG', 'ATTTGA', 'TTTGAA', 'TTGAAC', 'TGAACC', 'GAACCC', 'AACCCG', 'ACCCGG', 'CCCGGG', 'CCGGGA', 'CGGGAG', 'GGGAGG', 'GGAGGT', 'GAGGTG', 'AGGTGG', 'GGTGGA', 'GTGGAG', 'TGGAGG', 'GGAGGT', 'GAGGTT', 'AGGTTG', 'GGTTGC', 'GTTGCC', 'TTGCCG', 'TGCCGT', 'GCCGTG', 'CCGTGA', 'CGTGAG', 'GTGAGC', 'TGAGCT', 'GAGCTG', 'AGCTGA', 'GCTGAG', 'CTGAGA', 'TGAGAT', 'GAGATT', 'AGATTG', 'GATTGC', 'ATTGCG', 'TTGCGC', 'TGCGCC', 'GCGCCA', 'CGCCAT', 'GCCATT', 'CCATTG', 'CATTGC', 'ATTGCA', 'TTGCAC', 'TGCACT', 'GCACTC', 'CACTCC', 'ACTCCA', 'CTCCAG', 'TCCAGC', 'CCAGCC', 'CAGCCT', 'AGCCTG', 'GCCTGG', 'CCTGGG', 'CTGGGC', 'TGGGCA', 'GGGCAA', 'GGCAAC', 'GCAACA', 'CAACAA', 'AACAAG', 'ACAAGA', 'CAAGAG', 'AAGAGC', 'AGAGCA', 'GAGCAA', 'AGCAAA', 'GCAAAA', 'CAAAAC', 'AAAACT', 'AAACTC', 'AACTCT', 'ACTCTG', 'CTCTGT', 'TCTGTC', 'CTGTCT', 'TGTCTC', 'GTCTCA', 'TCTCAC', 'CTCACA', 'TCACAA', 'CACAAA', 'ACAAAA', 'CAAAAC']\n"
     ]
    }
   ],
   "source": [
    "x = df['seq'][0]\n",
    "sub = substrings(x, length)\n",
    "print(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-13T11:58:57.940830Z",
     "start_time": "2019-02-13T11:58:57.936025Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GGAGAATCATTTGAACCCGGGAGGTGGAGGTTGCCGTGAGCTGAGATTGCGCCATTGCACTCCAGCCTGGGCAACAAGAGCAAAACTCTGTCTCACAAAAC'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-13T11:58:57.947984Z",
     "start_time": "2019-02-13T11:58:57.943164Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we reduce to get the feature vector. Let $\\Phi_u(x)$ denote the number of occurrences of $u$ in $x$. The\n",
    "$k$-spectrum kernel is $K(x, x'):= \\sum_{u\\in A^k} \\Phi_u(x) \\Phi_u(x')$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It corresponds to a linear kernel over the feature space. So we may store all sequences in the feature space of all length 3 subsequences. The features will be sparse: at most $|x|-k+1$ non zero features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-13T11:58:57.955308Z",
     "start_time": "2019-02-13T11:58:57.950074Z"
    }
   },
   "outputs": [],
   "source": [
    "def encode(sub, voc):\n",
    "    enc = np.zeros(len(voc))\n",
    "    for s in sub:\n",
    "        i = voc[s]\n",
    "        enc[i] += 1\n",
    "    return enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-13T11:58:57.962915Z",
     "start_time": "2019-02-13T11:58:57.959069Z"
    }
   },
   "outputs": [],
   "source": [
    "encoding = encode(sub, voc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-13T11:58:57.980246Z",
     "start_time": "2019-02-13T11:58:57.974763Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute TF-IDF index of the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-13T11:58:57.987788Z",
     "start_time": "2019-02-13T11:58:57.982246Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary has size 64\n"
     ]
    }
   ],
   "source": [
    "letters = 'ATCG'\n",
    "length = 3\n",
    "voc = build_voc(letters, length)\n",
    "print('Vocabulary has size', len(voc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [00:00<00:00, 3187.31it/s]\n",
      "100%|██████████| 3000/3000 [00:01<00:00, 1871.76it/s]\n",
      "100%|██████████| 3000/3000 [00:01<00:00, 2343.89it/s]\n"
     ]
    }
   ],
   "source": [
    "tf_idfs = []\n",
    "for ind in range(3):\n",
    "    df = pd.read_csv('data/Xtr'+str(ind)+'.csv')\n",
    "    df2 = pd.read_csv('data/Xte'+str(ind)+'.csv')\n",
    "    tab = np.concatenate((df.values, df2.values))\n",
    "\n",
    "    tf = np.zeros((tab.shape[0], len(voc)))\n",
    "    for j in tqdm.tqdm(range(tf.shape[0])):\n",
    "        seq = tab[j, 1]\n",
    "        enc = encode(substrings(seq, length), voc)\n",
    "        tf[j, :] = enc\n",
    "    tf = (tf.T/tf.max(axis=1)).T # Frequency of each word in each string\n",
    "    idf = (tf != 0).sum(axis=0) # Number of strings where each word appears\n",
    "    tf_idf = tf*idf\n",
    "    tf_idfs.append(tf_idf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the embedded data matrices (exact matching)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-13T11:59:13.915756Z",
     "start_time": "2019-02-13T11:58:57.989981Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2000it [00:11, 167.85it/s]\n",
      "1000it [00:04, 216.43it/s]\n",
      "2000it [00:08, 227.15it/s]\n",
      "1000it [00:03, 310.96it/s]\n",
      "2000it [00:08, 241.69it/s]\n",
      "1000it [00:05, 199.04it/s]\n"
     ]
    }
   ],
   "source": [
    "for ind in range(3):\n",
    "    df = pd.read_csv('data/Xtr'+str(ind)+'.csv')\n",
    "    # TF-IDF reweighting\n",
    "    tf_idf = tf_idfs[ind]\n",
    "    j = 0\n",
    "    \n",
    "    df_emb = pd.DataFrame(columns = [str(i) for i in range(len(voc))])\n",
    "    for _, r in tqdm.tqdm(df.iterrows()):\n",
    "        i = r['Id']\n",
    "        seq = r['seq']\n",
    "        enc = encode(substrings(seq, length), voc)\n",
    "        df_emb.loc[i] = enc * tf_idf[j]\n",
    "        j+=1\n",
    "    df_emb.to_csv('data/'\n",
    "              + 'Xtr' +str(ind) + '_tfidf'+str(length)+'.csv', header = False, index = False, sep=\" \")\n",
    "    \n",
    "    df = pd.read_csv('data/Xte'+str(ind)+'.csv')\n",
    "    df_emb = pd.DataFrame(columns = [str(i) for i in range(len(voc))])\n",
    "    for _, r in tqdm.tqdm(df.iterrows()):\n",
    "        i = r['Id']\n",
    "        seq = r['seq']\n",
    "        enc = encode(substrings(seq, length), voc)\n",
    "        df_emb.loc[i] = enc * tf_idf[j]\n",
    "        j+=1\n",
    "    df_emb.to_csv('data/'\n",
    "              + 'Xte' +str(ind) + '_tfidf'+str(length)+'.csv', header = False, index = False, sep=\" \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
