{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T21:58:14.240477Z",
     "start_time": "2019-02-26T21:58:08.476653Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T21:58:14.270779Z",
     "start_time": "2019-02-26T21:58:14.243386Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(63)\n",
    "\n",
    "states = np.arange(4)\n",
    "observations = np.arange(4)\n",
    "\n",
    "pi_th = np.random.random(4)\n",
    "pi_th /= pi_th.sum()\n",
    "\n",
    "A_th = np.random.random((4, 4))\n",
    "i_zero = [0, 0, 0, 1, 1, 1, 2, 2, 3, 3]\n",
    "j_zero = [0, 2, 3, 0, 1, 3, 1, 2, 1, 2]\n",
    "A_th[i_zero, j_zero] = 0\n",
    "A_th /= A_th.sum(axis=1)[:, None]\n",
    "\n",
    "B_th = np.random.random((4, 4))\n",
    "B_th /= B_th.sum(axis=1)[:, None]\n",
    "\n",
    "def generate(A, B, pi, T):\n",
    "    x = []\n",
    "    y = []\n",
    "    for t in range(T):\n",
    "        if t == 0:\n",
    "            x.append(np.random.choice(states, p=pi))\n",
    "        else:\n",
    "            x.append(np.random.choice(states, p=A[x[-1]]))\n",
    "        y.append(np.random.choice(observations, p=B[x[-1]]))\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    return x, y\n",
    "\n",
    "x1, y1 = generate(A_th, B_th, pi_th, 250)\n",
    "x2, y2 = generate(A_th, B_th, pi_th, 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T21:58:14.277294Z",
     "start_time": "2019-02-26T21:58:14.272647Z"
    }
   },
   "outputs": [],
   "source": [
    "def loglikelihood(y, A, B, pi):\n",
    "    T = len(y)\n",
    "    n_s = A.shape[0]\n",
    "    \n",
    "    norm = np.empty(T)\n",
    "\n",
    "    alpha = np.empty((T, n_s))\n",
    "    alpha[0] = pi * B[:, y[0]]\n",
    "    norm[0] = 1/alpha[0].sum()\n",
    "    for t in range(T-1):\n",
    "        alpha[t+1] = B[:, y[t+1]] * A.T.dot(alpha[t])\n",
    "        norm[t+1] = 1/alpha[t+1].sum()\n",
    "        alpha[t+1] *= norm[t+1]\n",
    "\n",
    "    loglike = alpha[T-1].sum() - np.log(norm).sum()\n",
    "    return loglike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T21:58:14.288849Z",
     "start_time": "2019-02-26T21:58:14.280776Z"
    }
   },
   "outputs": [],
   "source": [
    "def forward_backward(y, A, B, pi):\n",
    "    T = len(y)\n",
    "    n_s = A.shape[0]\n",
    "    \n",
    "    norm = np.empty(T)\n",
    "\n",
    "    alpha = np.empty((T, n_s))\n",
    "    alpha[0] = pi * B[:, y[0]]\n",
    "    norm[0] = 1/alpha[0].sum()\n",
    "    alpha[0] *= norm[0]\n",
    "    for t in range(T-1):\n",
    "        alpha[t+1] = B[:, y[t+1]] * A.T.dot(alpha[t])\n",
    "        norm[t+1] = 1/alpha[t+1].sum()\n",
    "        alpha[t+1] *= norm[t+1]\n",
    "\n",
    "    beta = np.empty((T, n_s))\n",
    "    beta[T-1] = norm[T-1] * 1\n",
    "    beta[T-1] *= norm[T-1]\n",
    "    for t in range(T-2, -1, -1):\n",
    "        beta[t] = A.dot(beta[t+1] * B[:, y[t+1]])\n",
    "        beta[t] *= norm[t]\n",
    "\n",
    "    return alpha, beta, norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T21:58:14.302786Z",
     "start_time": "2019-02-26T21:58:14.292076Z"
    }
   },
   "outputs": [],
   "source": [
    "def update(y, A, B, pi, alpha, beta, norm):\n",
    "    T = len(y)\n",
    "    n_s = A.shape[0]\n",
    "    n_o = B.shape[1]\n",
    "    \n",
    "    new_pi = np.empty(n_s)\n",
    "    new_A = np.empty((n_s, n_s))\n",
    "    new_B = np.empty((n_s, n_o))\n",
    "    \n",
    "    for i in range(n_s):\n",
    "        new_pi[i] = alpha[0, i] * beta[0, i] / alpha[0].dot(beta[0])\n",
    "    \n",
    "    for i in range(n_s):\n",
    "        for j in range(n_s):\n",
    "            new_A[i, j] = sum(\n",
    "                [alpha[t, i] * A[i, j] * B[j, y[t+1]] * beta[t+1, j] for t in range(T-1)]\n",
    "            ) / sum(\n",
    "                [alpha[t, i] * beta[t, i] / norm[t] for t in range(T-1)]\n",
    "            )\n",
    "    for j in range(n_s):\n",
    "        for k in range(n_o):\n",
    "            new_B[j, k] = sum(\n",
    "                [alpha[t, j] * beta[t, j] / norm[t] for t in range(T) if y[t] == k]\n",
    "            ) / sum(\n",
    "                [alpha[t, j] * beta[t, j] / norm[t] for t in range(T)]\n",
    "            )\n",
    "            \n",
    "    return new_A, new_B, new_pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T21:58:14.309778Z",
     "start_time": "2019-02-26T21:58:14.304931Z"
    }
   },
   "outputs": [],
   "source": [
    "def baum_welch_step(y, A, B, pi):\n",
    "    alpha, beta, norm = forward_backward(y, A, B, pi)\n",
    "    return update(y, A, B, pi, alpha, beta, norm)\n",
    "\n",
    "def baum_welch(y, A0, B0, pi0, iterations=100):\n",
    "    A, B, pi = A0, B0, pi0\n",
    "    for it in tqdm.trange(iterations):\n",
    "        A, B, pi = baum_welch_step(y, A, B, pi)\n",
    "    return A, B, pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T21:58:14.324078Z",
     "start_time": "2019-02-26T21:58:14.312931Z"
    }
   },
   "outputs": [],
   "source": [
    "def baum_welch_step_dataset2(dataset, A, B, pi):\n",
    "    \n",
    "    n_s = A.shape[0]\n",
    "    n_o = B.shape[1]\n",
    "    \n",
    "    new_A_num = np.zeros((n_s, n_s))\n",
    "    new_A_den = np.zeros((n_s, n_s))\n",
    "    new_B_num = np.zeros((n_s, n_o))\n",
    "    new_B_den = np.zeros((n_s, n_o))\n",
    "    new_pi_num = np.zeros(n_s)\n",
    "    new_pi_den = np.zeros(n_s)\n",
    "    \n",
    "    for y in dataset:\n",
    "        T = len(y)\n",
    "        alpha, beta, norm = forward_backward(y, A, B, pi)\n",
    "        \n",
    "        for i in range(n_s):\n",
    "            new_pi_num[i] += alpha[t, i] * beta[t, i] / norm[t]\n",
    "            new_pi_den[i] += 1\n",
    "\n",
    "        for i in range(n_s):\n",
    "            for j in range(n_s):\n",
    "                new_A_num[i, j] += sum(\n",
    "                    [alpha[t, i] * A[i, j] * B[j, y[t+1]] * beta[t+1, j] for t in range(T-1)]\n",
    "                )\n",
    "                new_A_den[i, j] += sum(\n",
    "                    [alpha[t, i] * beta[t, i] / norm[t] for t in range(T-1)]\n",
    "                )\n",
    "        for j in range(n_s):\n",
    "            for k in range(n_o):\n",
    "                new_B_num[j, k] += sum(\n",
    "                    [alpha[t, j] * beta[t, j] / norm[t] for t in range(T-1) if y[t] == k]\n",
    "                )\n",
    "                new_B_den[j, k] += sum(\n",
    "                    [alpha[t, j] * beta[t, j] / norm[t] for t in range(T-1)]\n",
    "                )\n",
    "\n",
    "    return new_A_num/new_A_den, new_B_num/new_B_den, new_pi_num/new_pi_den\n",
    "\n",
    "def baum_welch_dataset2(dataset, A0, B0, pi0, iterations=100):\n",
    "    A, B, pi = A0, B0, pi0\n",
    "    for it in tqdm.trange(iterations):\n",
    "        A, B, pi = baum_welch_step_dataset2(dataset, A, B, pi)\n",
    "    return A, B, pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T22:33:39.778224Z",
     "start_time": "2019-02-26T22:33:39.765249Z"
    }
   },
   "outputs": [],
   "source": [
    "def baum_welch_step_dataset(dataset, A, B, pi):\n",
    "    \n",
    "    n_s = A.shape[0]\n",
    "    n_o = B.shape[1]\n",
    "    \n",
    "    new_A_num = np.zeros((n_s, n_s))\n",
    "    new_A_den = np.zeros((n_s, n_s))\n",
    "    new_B_num = np.zeros((n_s, n_o))\n",
    "    new_B_den = np.zeros((n_s, n_o))\n",
    "    new_pi_num = np.zeros(n_s)\n",
    "    new_pi_den = np.zeros(n_s)\n",
    "    \n",
    "    for y in dataset:\n",
    "        T = len(y)\n",
    "        alpha, beta, norm = forward_backward(y, A, B, pi)\n",
    "        \n",
    "        new_A_num += (\n",
    "            alpha[:-1, :, None] * A[None, :, :] * B[:, y[1:]].T[:, None, :] * beta[1:, None, :]\n",
    "        ).sum(axis=0)\n",
    "        new_A_den += (\n",
    "            alpha[:-1, :, None] * beta[:-1, :, None] / norm[:-1, None, None]\n",
    "        ).sum(axis=0)\n",
    "        \n",
    "        onehot_encoder = OneHotEncoder(sparse=False, categories=\"auto\")\n",
    "        y_binary = onehot_encoder.fit_transform(y[:, None]).astype(int)\n",
    "        new_B_num += (\n",
    "            y_binary[:-1, None, :] * alpha[:-1, :, None] * beta[:-1, :, None] / norm[:-1, None, None]\n",
    "        ).sum(axis=0)\n",
    "        new_B_den += (\n",
    "            alpha[:-1, :, None] * beta[:-1, :, None] / norm[:-1, None, None]\n",
    "        ).sum(axis=0)\n",
    "        \n",
    "        new_pi_num += alpha[0, :] * beta[0, :] / norm[0]\n",
    "        new_pi_den += 1\n",
    "\n",
    "    return new_A_num/new_A_den, new_B_num/new_B_den, new_pi_num/new_pi_den\n",
    "\n",
    "def baum_welch_dataset(dataset, A0, B0, pi0, iterations=100):\n",
    "    A, B, pi = A0, B0, pi0\n",
    "    for it in tqdm.trange(iterations):\n",
    "        A, B, pi = baum_welch_step_dataset(dataset, A, B, pi)\n",
    "    return A, B, pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T21:58:14.344945Z",
     "start_time": "2019-02-26T21:58:14.338858Z"
    }
   },
   "outputs": [],
   "source": [
    "def baum_welch_dna(dataset, iterations=100):\n",
    "    np.random.seed(63)\n",
    "    A_guess = np.array([\n",
    "        [  0,   1,   0,   0,], # exon 1 => exon 2\n",
    "        [  0,   0,   1,   0,], # exon 2 => exon 3\n",
    "        [0.5,   0,   0, 0.5,], # exon 3 => exon 1 or intron\n",
    "        [0.5,   0,   0, 0.5,],\n",
    "    ])\n",
    "    A0 = np.random.random((4, 4)) * A_guess\n",
    "    A0 /= A0.sum(axis=1)[:, None]\n",
    "    \n",
    "    B0 = np.random.random((4, 4)) / 4\n",
    "    B0 /= B0.sum(axis=1)[:, None]\n",
    "    \n",
    "    pi0 = np.random.random(4)\n",
    "    pi0 /= pi0.sum()\n",
    "    \n",
    "    print(\"\\nInitial values\")\n",
    "    print(A0)\n",
    "    print(B0)\n",
    "    print(pi0)\n",
    "\n",
    "    A, B, pi = baum_welch_dataset(dataset, A0, B0, pi0, iterations)\n",
    "    \n",
    "    print(\"Estimation\")\n",
    "    print(A)\n",
    "    print(B)\n",
    "    print(pi)\n",
    "    \n",
    "    return A, B, pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T21:58:14.350875Z",
     "start_time": "2019-02-26T21:58:14.347036Z"
    }
   },
   "outputs": [],
   "source": [
    "def translate(dna_string):\n",
    "    dna_string = dna_string.replace(\"A\", \"0\")\n",
    "    dna_string = dna_string.replace(\"T\", \"1\")\n",
    "    dna_string = dna_string.replace(\"G\", \"2\")\n",
    "    dna_string = dna_string.replace(\"C\", \"3\")\n",
    "    seq = list(dna_string)\n",
    "    return np.array(seq).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T21:58:20.854058Z",
     "start_time": "2019-02-26T21:58:14.353181Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 6/100 [00:00<00:01, 52.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initial values\n",
      "[[0.         1.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.54819171 0.         0.         0.45180829]\n",
      " [0.63018735 0.         0.         0.36981265]]\n",
      "[[0.28091143 0.00260081 0.43141308 0.28507468]\n",
      " [0.27725454 0.26157888 0.20000889 0.26115768]\n",
      " [0.09972905 0.41371784 0.01206804 0.47448506]\n",
      " [0.24094784 0.26725151 0.34782094 0.14397971]]\n",
      "[0.19152753 0.29893667 0.17995657 0.32957923]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:02<00:00, 49.79it/s]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimation\n",
      "[[0.         1.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.26296646 0.         0.         0.73703354]\n",
      " [0.24723052 0.         0.         0.75276948]]\n",
      "[[4.21564794e-03 9.24168892e-08 2.56331972e-01 7.39452288e-01]\n",
      " [4.61894839e-01 2.57029640e-01 4.26576457e-03 2.76809757e-01]\n",
      " [1.92338325e-01 1.55122981e-01 3.66416755e-01 2.86121939e-01]\n",
      " [2.56775762e-01 3.29383731e-01 3.26164047e-01 8.76764593e-02]]\n",
      "[5.00719479e-25 9.07281066e-15 4.40676182e-07 4.16918117e+00]\n",
      "\n",
      "Initial values\n",
      "[[0.         1.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.54819171 0.         0.         0.45180829]\n",
      " [0.63018735 0.         0.         0.36981265]]\n",
      "[[0.28091143 0.00260081 0.43141308 0.28507468]\n",
      " [0.27725454 0.26157888 0.20000889 0.26115768]\n",
      " [0.09972905 0.41371784 0.01206804 0.47448506]\n",
      " [0.24094784 0.26725151 0.34782094 0.14397971]]\n",
      "[0.19152753 0.29893667 0.17995657 0.32957923]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:02<00:00, 45.58it/s]\n",
      "  6%|▌         | 6/100 [00:00<00:01, 51.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimation\n",
      "[[0.         1.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.48346029 0.         0.         0.51653971]\n",
      " [0.15063821 0.         0.         0.84936179]]\n",
      "[[7.12170306e-02 1.51675850e-01 4.59942987e-01 3.17164132e-01]\n",
      " [1.79586182e-08 1.70568690e-01 3.46250183e-03 8.25968791e-01]\n",
      " [3.05612295e-01 2.12199178e-01 6.32800285e-02 4.18908499e-01]\n",
      " [3.22285956e-01 2.20790914e-01 3.28066209e-01 1.28856920e-01]]\n",
      "[3.34456901e-12 4.77713443e-12 2.25575633e+00 2.47685397e+00]\n",
      "\n",
      "Initial values\n",
      "[[0.         1.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.54819171 0.         0.         0.45180829]\n",
      " [0.63018735 0.         0.         0.36981265]]\n",
      "[[0.28091143 0.00260081 0.43141308 0.28507468]\n",
      " [0.27725454 0.26157888 0.20000889 0.26115768]\n",
      " [0.09972905 0.41371784 0.01206804 0.47448506]\n",
      " [0.24094784 0.26725151 0.34782094 0.14397971]]\n",
      "[0.19152753 0.29893667 0.17995657 0.32957923]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:01<00:00, 50.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimation\n",
      "[[0.         1.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.38338466 0.         0.         0.61661534]\n",
      " [0.22920493 0.         0.         0.77079507]]\n",
      "[[1.52075643e-01 1.78674557e-01 3.17861365e-01 3.51388435e-01]\n",
      " [1.01225036e-01 1.70184374e-01 1.03373855e-04 7.28487216e-01]\n",
      " [3.42915317e-01 4.03783490e-01 2.59367743e-04 2.53041825e-01]\n",
      " [2.15777171e-01 2.23709875e-01 5.21349262e-01 3.91636926e-02]]\n",
      "[8.61173400e-45 1.35291046e+00 7.64336400e-01 1.60384291e+00]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_samples = 10\n",
    "iterations = 100\n",
    "for d in range(3):\n",
    "    dataset_string = pd.read_csv(\"data/Xtr{}.csv\".format(d), index_col=0)\n",
    "    dataset = [\n",
    "        translate(dna_string)\n",
    "        for dna_string in dataset_string.values[:, 0]\n",
    "    ]\n",
    "    A, B, pi = baum_welch_dna(dataset[:n_samples], iterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Marginalized count kernel (Tsuda 2002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T22:38:11.685946Z",
     "start_time": "2019-02-26T22:38:11.673635Z"
    }
   },
   "outputs": [],
   "source": [
    "def first_order_marginalized_count(y, A, B, pi):\n",
    "    alpha, beta, norm = forward_backward(y, A, B, pi)\n",
    "    onehot_encoder = OneHotEncoder(sparse=False, categories=\"auto\")\n",
    "    y_binary = onehot_encoder.fit_transform(y[:, None]).astype(int)\n",
    "    return (y_binary[:, :, None] * alpha[:, None, :]).mean(axis=0).flatten()\n",
    "\n",
    "def first_order_mc_features(dataset, A, B, pi):\n",
    "    return np.array([\n",
    "        marginalized_count(y, A, B, pi)\n",
    "        for y in dataset\n",
    "    ])\n",
    "\n",
    "def second_order_marginalized_count(y, A, B, pi):\n",
    "    alpha, beta, norm = forward_backward(y, A, B, pi)\n",
    "    ksi = alpha[:-1, :, None] * A[None, :, :] * B[:, y[1:]].T[:, None, :] * beta[1:, None, :]\n",
    "    onehot_encoder = OneHotEncoder(sparse=False, categories=\"auto\")\n",
    "    y_binary = onehot_encoder.fit_transform(y[:, None]).astype(int)\n",
    "    # axes : t, i1, k1, i2, k2\n",
    "    return (\n",
    "        y_binary[:-1, :, None, None, None] *\n",
    "        y_binary[1:, None, None, :, None] *\n",
    "        ksi[:, None, :, None, :]\n",
    "    ).mean(axis=0).flatten()\n",
    "\n",
    "def second_order_mc_features(dataset, A, B, pi):\n",
    "    return np.array([\n",
    "        second_order_marginalized_count(y, A, B, pi)\n",
    "        for y in dataset\n",
    "    ])\n",
    "\n",
    "def mc_features(dataset, A, B, pi, order):\n",
    "    if order == 1:\n",
    "        return first_order_mc_features(dataset, A, B, pi)\n",
    "    elif order == 2:\n",
    "        return second_order_mc_features(dataset, A, B, pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T22:38:49.865604Z",
     "start_time": "2019-02-26T22:38:12.298980Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:37<00:00, 12.46s/it]\n"
     ]
    }
   ],
   "source": [
    "for d in tqdm.trange(3):\n",
    "    for order in [1, 2]:\n",
    "        A = np.array(pd.read_csv(\"data/HMM_{}_A.csv\".format(d), index_col=0))\n",
    "        B = np.array(pd.read_csv(\"data/HMM_{}_B.csv\".format(d), index_col=0))\n",
    "        pi = np.array(pd.read_csv(\"data/HMM_{}_pi.csv\".format(d), index_col=0))[:, 0]\n",
    "\n",
    "        train_string = pd.read_csv(\"data/Xtr{}.csv\".format(d), index_col=0)\n",
    "        train_num = [\n",
    "            translate(dna_string)\n",
    "            for dna_string in train_string.values[:, 0]\n",
    "        ]\n",
    "        Xtr = mc_features(train_num, A, B, pi, order)\n",
    "        pd.DataFrame(Xtr).to_csv(\"data/Xtr{}_HMM_MCK{}.csv\".format(d, order), index=False, header=False, sep=\" \")\n",
    "\n",
    "        test_string = pd.read_csv(\"data/Xte{}.csv\".format(d), index_col=0)\n",
    "        test_num = [\n",
    "            translate(dna_string)\n",
    "            for dna_string in test_string.values[:, 0]\n",
    "        ]\n",
    "        Xte = mc_features(test_num, A, B, pi, order)\n",
    "        pd.DataFrame(Xte).to_csv(\"data/Xte{}_HMM_MCK{}.csv\".format(d, order), index=False, header=False, sep=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:optim]",
   "language": "python",
   "name": "conda-env-optim-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
