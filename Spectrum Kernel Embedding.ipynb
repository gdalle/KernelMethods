{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-13T11:58:57.846700Z",
     "start_time": "2019-02-13T11:58:56.876613Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-13T11:58:57.873845Z",
     "start_time": "2019-02-13T11:58:57.850955Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/Xtr0.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-13T11:58:57.892666Z",
     "start_time": "2019-02-13T11:58:57.876106Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>GGAGAATCATTTGAACCCGGGAGGTGGAGGTTGCCGTGAGCTGAGA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ACCCTGCCTACACCGCGGCGGGGACAGGTGGAGGTTTCAACCCCTG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>TGCAAATCTGTAAGCATTTCTCAGGCAATGAATTATGTCAACACAA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>GCGGGACGTGGGCGTCGAGGGTAAGGATATCTGCAGAAGTACTGTC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>GGAGAATAGCATGTATCCGAGAGGTGGAGCTGGCAGTGAGCCGAGA...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id                                                seq\n",
       "0   0  GGAGAATCATTTGAACCCGGGAGGTGGAGGTTGCCGTGAGCTGAGA...\n",
       "1   1  ACCCTGCCTACACCGCGGCGGGGACAGGTGGAGGTTTCAACCCCTG...\n",
       "2   2  TGCAAATCTGTAAGCATTTCTCAGGCAATGAATTATGTCAACACAA...\n",
       "3   3  GCGGGACGTGGGCGTCGAGGGTAAGGATATCTGCAGAAGTACTGTC...\n",
       "4   4  GGAGAATAGCATGTATCCGAGAGGTGGAGCTGGCAGTGAGCCGAGA..."
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All sequences is this set have length 101."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-13T11:58:57.901544Z",
     "start_time": "2019-02-13T11:58:57.895814Z"
    }
   },
   "outputs": [],
   "source": [
    "letters = 'ATCG'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-13T11:58:57.907090Z",
     "start_time": "2019-02-13T11:58:57.904370Z"
    }
   },
   "outputs": [],
   "source": [
    "length = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-13T11:58:57.918703Z",
     "start_time": "2019-02-13T11:58:57.910790Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AAA': 0, 'AAT': 1, 'AAC': 2, 'AAG': 3, 'ATA': 4, 'ATT': 5, 'ATC': 6, 'ATG': 7, 'ACA': 8, 'ACT': 9, 'ACC': 10, 'ACG': 11, 'AGA': 12, 'AGT': 13, 'AGC': 14, 'AGG': 15, 'TAA': 16, 'TAT': 17, 'TAC': 18, 'TAG': 19, 'TTA': 20, 'TTT': 21, 'TTC': 22, 'TTG': 23, 'TCA': 24, 'TCT': 25, 'TCC': 26, 'TCG': 27, 'TGA': 28, 'TGT': 29, 'TGC': 30, 'TGG': 31, 'CAA': 32, 'CAT': 33, 'CAC': 34, 'CAG': 35, 'CTA': 36, 'CTT': 37, 'CTC': 38, 'CTG': 39, 'CCA': 40, 'CCT': 41, 'CCC': 42, 'CCG': 43, 'CGA': 44, 'CGT': 45, 'CGC': 46, 'CGG': 47, 'GAA': 48, 'GAT': 49, 'GAC': 50, 'GAG': 51, 'GTA': 52, 'GTT': 53, 'GTC': 54, 'GTG': 55, 'GCA': 56, 'GCT': 57, 'GCC': 58, 'GCG': 59, 'GGA': 60, 'GGT': 61, 'GGC': 62, 'GGG': 63}\n"
     ]
    }
   ],
   "source": [
    "def build_voc(letters, length):\n",
    "    vocl = [''.join(x) for x in itertools.product(letters, repeat=length)]\n",
    "    voc = {}\n",
    "    i = 0\n",
    "    for v in vocl:\n",
    "        voc[v] = i\n",
    "        i+=1\n",
    "    return voc\n",
    "voc = build_voc(letters, length)\n",
    "print(voc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\Phi_u(x)$ is the number of occurrences of u in x (without gaps) : *spectrum kernel* (Leslie et al., 2002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-13T11:58:57.926063Z",
     "start_time": "2019-02-13T11:58:57.921356Z"
    }
   },
   "outputs": [],
   "source": [
    "def substrings(x, length):\n",
    "    n = len(x)\n",
    "    sub = []\n",
    "    assert n>=length, 'seq too small'\n",
    "    for i in range(n-length+1):\n",
    "        curr = x[i:i+length]\n",
    "        sub.append(curr)\n",
    "    return sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-13T11:58:57.933923Z",
     "start_time": "2019-02-13T11:58:57.927943Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GGA', 'GAG', 'AGA', 'GAA', 'AAT', 'ATC', 'TCA', 'CAT', 'ATT', 'TTT', 'TTG', 'TGA', 'GAA', 'AAC', 'ACC', 'CCC', 'CCG', 'CGG', 'GGG', 'GGA', 'GAG', 'AGG', 'GGT', 'GTG', 'TGG', 'GGA', 'GAG', 'AGG', 'GGT', 'GTT', 'TTG', 'TGC', 'GCC', 'CCG', 'CGT', 'GTG', 'TGA', 'GAG', 'AGC', 'GCT', 'CTG', 'TGA', 'GAG', 'AGA', 'GAT', 'ATT', 'TTG', 'TGC', 'GCG', 'CGC', 'GCC', 'CCA', 'CAT', 'ATT', 'TTG', 'TGC', 'GCA', 'CAC', 'ACT', 'CTC', 'TCC', 'CCA', 'CAG', 'AGC', 'GCC', 'CCT', 'CTG', 'TGG', 'GGG', 'GGC', 'GCA', 'CAA', 'AAC', 'ACA', 'CAA', 'AAG', 'AGA', 'GAG', 'AGC', 'GCA', 'CAA', 'AAA', 'AAA', 'AAC', 'ACT', 'CTC', 'TCT', 'CTG', 'TGT', 'GTC', 'TCT', 'CTC', 'TCA', 'CAC', 'ACA', 'CAA', 'AAA', 'AAA', 'AAC']\n"
     ]
    }
   ],
   "source": [
    "x = df['seq'][0]\n",
    "sub = substrings(x, 3)\n",
    "print(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-13T11:58:57.940830Z",
     "start_time": "2019-02-13T11:58:57.936025Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GGAGAATCATTTGAACCCGGGAGGTGGAGGTTGCCGTGAGCTGAGATTGCGCCATTGCACTCCAGCCTGGGCAACAAGAGCAAAACTCTGTCTCACAAAAC'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-13T11:58:57.947984Z",
     "start_time": "2019-02-13T11:58:57.943164Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we reduce to get the feature vector. Let $\\Phi_u(x)$ denote the number of occurrences of $u$ in $x$. The\n",
    "$k$-spectrum kernel is $K(x, x'):= \\sum_{u\\in A^k} \\Phi_u(x) \\Phi_u(x')$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It corresponds to a linear kernel over the feature space. So we may store all sequences in the feature space of all length 3 subsequences. The features will be sparse: at most $|x|-k+1$ non zero features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-13T11:58:57.955308Z",
     "start_time": "2019-02-13T11:58:57.950074Z"
    }
   },
   "outputs": [],
   "source": [
    "def encode(sub, voc):\n",
    "    enc = np.zeros(len(voc))\n",
    "    for s in sub:\n",
    "        i = voc[s]\n",
    "        enc[i] += 1\n",
    "    return enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-13T11:58:57.962915Z",
     "start_time": "2019-02-13T11:58:57.959069Z"
    }
   },
   "outputs": [],
   "source": [
    "encoding = encode(sub, voc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-13T11:58:57.972813Z",
     "start_time": "2019-02-13T11:58:57.966560Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4. 1. 4. 1. 0. 3. 1. 0. 2. 2. 1. 0. 3. 0. 3. 2. 0. 0. 0. 0. 0. 1. 0. 4.\n",
      " 2. 2. 1. 0. 3. 1. 3. 2. 4. 2. 2. 1. 0. 0. 3. 3. 2. 1. 1. 2. 0. 1. 1. 1.\n",
      " 2. 1. 0. 6. 0. 1. 1. 2. 3. 1. 3. 1. 3. 2. 1. 2.]\n"
     ]
    }
   ],
   "source": [
    "print(encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-13T11:58:57.980246Z",
     "start_time": "2019-02-13T11:58:57.974763Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the embedded data matrices (exact matching)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-13T11:58:57.987788Z",
     "start_time": "2019-02-13T11:58:57.982246Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary has size 1024\n"
     ]
    }
   ],
   "source": [
    "letters = 'ATCG'\n",
    "length = 5\n",
    "voc = build_voc(letters, length)\n",
    "print('Vocabulary has size', len(voc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-13T11:59:13.915756Z",
     "start_time": "2019-02-13T11:58:57.989981Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2000it [00:17, 115.29it/s]\n",
      "2000it [00:19, 104.94it/s]\n",
      "2000it [00:31, 39.89it/s]\n"
     ]
    }
   ],
   "source": [
    "for ind in range(3):\n",
    "    df = pd.read_csv('data/Xtr'+str(ind)+'.csv')\n",
    "    df_emb = pd.DataFrame(columns = [str(i) for i in range(len(voc))])\n",
    "    for _, r in tqdm.tqdm(df.iterrows()):\n",
    "        i = r['Id']\n",
    "        seq = r['seq']\n",
    "        enc = encode(substrings(seq, length), voc)\n",
    "        df_emb.loc[i] = enc\n",
    "    df_emb.to_csv('data/'\n",
    "              + 'Xtr' +str(ind) + '_spectr'+str(length)+'.csv', header = False, index = False, sep=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-13T11:59:19.742205Z",
     "start_time": "2019-02-13T11:59:13.917018Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [00:05, 181.18it/s]\n",
      "1000it [00:05, 115.34it/s]\n",
      "1000it [00:05, 185.48it/s]\n"
     ]
    }
   ],
   "source": [
    "for ind in range(3):\n",
    "    df = pd.read_csv('data/Xte'+str(ind)+'.csv')\n",
    "    df_emb = pd.DataFrame(columns = [str(i) for i in range(len(voc))])\n",
    "    for _, r in tqdm.tqdm(df.iterrows()):\n",
    "        i = r['Id']\n",
    "        seq = r['seq']\n",
    "        enc = encode(substrings(seq, length), voc)\n",
    "        df_emb.loc[i] = enc\n",
    "    df_emb.to_csv('data/'\n",
    "              + 'Xte' +str(ind) + '_spectr'+str(length)+'.csv', header = False, index = False, sep=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use suffix tree for mismatches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building suffix tree using Ukkonen's algorithm (external lib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-13T11:59:19.753333Z",
     "start_time": "2019-02-13T11:59:19.747424Z"
    }
   },
   "outputs": [],
   "source": [
    "from suffix_trees import STree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-13T11:58:56.912Z"
    }
   },
   "outputs": [],
   "source": [
    "string = 'BANANA' # has 6 suffixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-13T11:58:56.914Z"
    }
   },
   "outputs": [],
   "source": [
    "st = STree.STree(\"BANANA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-13T11:58:56.916Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.find_all('AN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-13T11:58:56.918Z"
    }
   },
   "outputs": [],
   "source": [
    "letters = 'ATCG'\n",
    "length = 3\n",
    "voc = build_voc(letters, length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-13T11:58:56.919Z"
    }
   },
   "outputs": [],
   "source": [
    "s0 = df['seq'][0]\n",
    "w = 'AAG'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-13T11:58:56.921Z"
    }
   },
   "outputs": [],
   "source": [
    "st0 = STree.STree(s0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build words at 1 Hamming distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-13T11:58:56.922Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_1_neighborhood(w):\n",
    "    nset = []\n",
    "    for i in range(len(w)):\n",
    "        for j in letters:\n",
    "            nset.append(w[:i]+j+w[i+1:])\n",
    "\n",
    "    nset = list(set(nset))\n",
    "    return nset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-13T11:58:56.923Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AAG', 'AAC', 'AAA', 'ACG', 'TAG', 'AGG', 'ATG', 'CAG', 'GAG', 'AAT']\n"
     ]
    }
   ],
   "source": [
    "nset = build_1_neighborhood(w)\n",
    "print(nset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-13T11:58:56.925Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nset) # 3+3+3 + 1 exact matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-13T11:58:56.927Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([len(st0.find_all(n)) for n in nset]) # all 1-Hamming matches of w in s0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-13T11:58:56.929Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AAA': ['AGA', 'AAC', 'ATA', 'AAG', 'AAA', 'TAA', 'CAA', 'GAA', 'AAT', 'ACA'], 'AAT': ['GAT', 'AAC', 'AAG', 'CAT', 'TAT', 'AAA', 'AGT', 'ATT', 'ACT', 'AAT'], 'AAC': ['ACC', 'AGC', 'AAC', 'AAG', 'GAC', 'TAC', 'AAA', 'CAC', 'ATC', 'AAT'], 'AAG': ['AAG', 'AAC', 'AAA', 'ACG', 'TAG', 'AGG', 'ATG', 'CAG', 'GAG', 'AAT'], 'ATA': ['AGA', 'GTA', 'CTA', 'ATA', 'AAA', 'TTA', 'ATT', 'ATG', 'ATC', 'ACA'], 'ATT': ['TTT', 'ATA', 'GTT', 'AGT', 'ATC', 'CTT', 'ATT', 'ATG', 'ACT', 'AAT'], 'ATC': ['ACC', 'AGC', 'AAC', 'ATA', 'CTC', 'TTC', 'GTC', 'ATT', 'ATG', 'ATC'], 'ATG': ['CTG', 'AAG', 'ATA', 'ACG', 'GTG', 'TTG', 'AGG', 'ATT', 'ATG', 'ATC'], 'ACA': ['AGA', 'ACC', 'ATA', 'AAA', 'CCA', 'GCA', 'TCA', 'ACG', 'ACT', 'ACA'], 'ACT': ['TCT', 'ACC', 'CCT', 'AGT', 'GCT', 'ATT', 'ACG', 'ACT', 'AAT', 'ACA'], 'ACC': ['ACC', 'GCC', 'AAC', 'AGC', 'TCC', 'ACT', 'CCC', 'ACG', 'ATC', 'ACA'], 'ACG': ['ACC', 'AAG', 'GCG', 'CCG', 'ACT', 'AGG', 'ACG', 'ACA', 'TCG', 'ATG'], 'AGA': ['CGA', 'AGA', 'ATA', 'AAA', 'TGA', 'AGT', 'GGA', 'AGG', 'AGC', 'ACA'], 'AGT': ['GGT', 'AGA', 'AGC', 'TGT', 'AGT', 'AGG', 'ATT', 'CGT', 'ACT', 'AAT'], 'AGC': ['ACC', 'GGC', 'AAC', 'AGA', 'AGT', 'ATC', 'CGC', 'AGG', 'TGC', 'AGC'], 'AGG': ['AGA', 'AAG', 'ACG', 'AGT', 'CGG', 'AGG', 'ATG', 'GGG', 'AGC', 'TGG'], 'TAA': ['TAC', 'AAA', 'TAT', 'TGA', 'TAG', 'TAA', 'TTA', 'CAA', 'TCA', 'GAA'], 'TAT': ['GAT', 'TCT', 'TTT', 'TGT', 'TAC', 'CAT', 'TAT', 'TAG', 'TAA', 'AAT'], 'TAC': ['AAC', 'GAC', 'TAC', 'TAT', 'TAG', 'TCC', 'TAA', 'TTC', 'CAC', 'TGC'], 'TAG': ['AAG', 'TAC', 'TAT', 'TAG', 'TAA', 'TTG', 'CAG', 'GAG', 'TCG', 'TGG'], 'TTA': ['GTA', 'CTA', 'ATA', 'TTT', 'TGA', 'TAA', 'TTC', 'TTG', 'TTA', 'TCA'], 'TTT': ['TCT', 'TTT', 'TGT', 'TAT', 'GTT', 'TTC', 'CTT', 'TTA', 'TTG', 'ATT'], 'TTC': ['TTT', 'TAC', 'CTC', 'TCC', 'TTC', 'TTG', 'TTA', 'GTC', 'TGC', 'ATC'], 'TTG': ['CTG', 'TTT', 'GTG', 'TAG', 'TTG', 'TTC', 'TTA', 'ATG', 'TCG', 'TGG'], 'TCA': ['TCT', 'CCA', 'TGA', 'TAA', 'GCA', 'TCC', 'TTA', 'TCA', 'TCG', 'ACA'], 'TCT': ['TCT', 'TTT', 'TGT', 'TAT', 'CCT', 'TCC', 'GCT', 'TCA', 'ACT', 'TCG'], 'TCC': ['ACC', 'GCC', 'TCT', 'TAC', 'TCC', 'TTC', 'CCC', 'TCA', 'TGC', 'TCG'], 'TCG': ['TCT', 'GCG', 'TAG', 'CCG', 'TCC', 'TTG', 'TCA', 'ACG', 'TCG', 'TGG'], 'TGA': ['CGA', 'AGA', 'TGT', 'TGA', 'TAA', 'GGA', 'TTA', 'TCA', 'TGC', 'TGG'], 'TGT': ['GGT', 'TCT', 'TTT', 'TGT', 'TAT', 'AGT', 'TGA', 'TGC', 'CGT', 'TGG'], 'TGC': ['GGC', 'TGT', 'TAC', 'TGA', 'TCC', 'TTC', 'CGC', 'TGC', 'AGC', 'TGG'], 'TGG': ['TGT', 'TGA', 'TAG', 'TTG', 'CGG', 'AGG', 'TGC', 'TCG', 'GGG', 'TGG'], 'CAA': ['CGA', 'CTA', 'AAA', 'CAT', 'CCA', 'TAA', 'CAC', 'CAA', 'CAG', 'GAA'], 'CAT': ['GAT', 'CAT', 'TAT', 'CCT', 'CTT', 'CAC', 'CAA', 'CAG', 'CGT', 'AAT'], 'CAC': ['AAC', 'GAC', 'CTC', 'TAC', 'CAT', 'CAC', 'CCC', 'CGC', 'CAA', 'CAG'], 'CAG': ['CTG', 'AAG', 'CAT', 'TAG', 'CCG', 'CGG', 'CAA', 'CAC', 'CAG', 'GAG'], 'CTA': ['CTG', 'CGA', 'GTA', 'CTA', 'ATA', 'CTC', 'CCA', 'CTT', 'TTA', 'CAA'], 'CTT': ['CTG', 'TTT', 'CTA', 'CTC', 'CAT', 'GTT', 'CCT', 'CTT', 'ATT', 'CGT'], 'CTC': ['CTG', 'CTA', 'CTC', 'TTC', 'CTT', 'CAC', 'GTC', 'CCC', 'CGC', 'ATC'], 'CTG': ['CTG', 'CTA', 'CTC', 'GTG', 'CCG', 'TTG', 'CTT', 'CGG', 'ATG', 'CAG'], 'CCA': ['CGA', 'CTA', 'CCA', 'CCT', 'GCA', 'CCG', 'CCC', 'CAA', 'TCA', 'ACA'], 'CCT': ['TCT', 'CAT', 'CCT', 'CCA', 'CCG', 'GCT', 'CTT', 'CCC', 'CGT', 'ACT'], 'CCC': ['ACC', 'GCC', 'CTC', 'CCA', 'CCT', 'TCC', 'CCG', 'CAC', 'CCC', 'CGC'], 'CCG': ['CTG', 'GCG', 'CCA', 'CCT', 'CCG', 'CGG', 'CCC', 'ACG', 'CAG', 'TCG'], 'CGA': ['CGA', 'AGA', 'CTA', 'TGA', 'CCA', 'GGA', 'CGC', 'CAA', 'CGG', 'CGT'], 'CGT': ['GGT', 'CGA', 'TGT', 'CAT', 'AGT', 'CCT', 'CTT', 'CGC', 'CGG', 'CGT'], 'CGC': ['CGA', 'GGC', 'CTC', 'CAC', 'CGC', 'CCC', 'CGG', 'TGC', 'CGT', 'AGC'], 'CGG': ['CTG', 'CGA', 'CGT', 'CCG', 'CGG', 'AGG', 'CGC', 'CAG', 'GGG', 'TGG'], 'GAA': ['GAT', 'GTA', 'GAC', 'AAA', 'TAA', 'GCA', 'GGA', 'CAA', 'GAA', 'GAG'], 'GAT': ['GGT', 'GAT', 'GAC', 'CAT', 'TAT', 'GTT', 'GCT', 'GAA', 'GAG', 'AAT'], 'GAC': ['GAT', 'GCC', 'GGC', 'AAC', 'GAC', 'TAC', 'GTC', 'CAC', 'GAA', 'GAG'], 'GAG': ['GAT', 'AAG', 'GCG', 'GAC', 'GTG', 'TAG', 'CAG', 'GGG', 'GAA', 'GAG'], 'GTA': ['GTA', 'CTA', 'ATA', 'GTT', 'GTG', 'GCA', 'GGA', 'TTA', 'GTC', 'GAA'], 'GTT': ['GGT', 'GAT', 'TTT', 'GTA', 'GTT', 'GTG', 'GCT', 'CTT', 'GTC', 'ATT'], 'GTC': ['GCC', 'GGC', 'GTA', 'GAC', 'CTC', 'GTT', 'GTG', 'TTC', 'GTC', 'ATC'], 'GTG': ['CTG', 'GTA', 'GCG', 'GTT', 'GTG', 'TTG', 'GTC', 'ATG', 'GGG', 'GAG'], 'GCA': ['GCC', 'GTA', 'GCG', 'CCA', 'GCA', 'GGA', 'GCT', 'TCA', 'GAA', 'ACA'], 'GCT': ['GGT', 'GAT', 'TCT', 'GCC', 'GCG', 'CCT', 'GTT', 'GCA', 'GCT', 'ACT'], 'GCC': ['ACC', 'GCC', 'GGC', 'GAC', 'GCG', 'TCC', 'GCA', 'GCT', 'CCC', 'GTC'], 'GCG': ['GCC', 'GCG', 'GTG', 'CCG', 'GCA', 'GCT', 'ACG', 'GGG', 'GAG', 'TCG'], 'GGA': ['GGT', 'CGA', 'AGA', 'GGC', 'GTA', 'TGA', 'GCA', 'GGA', 'GGG', 'GAA'], 'GGT': ['GGT', 'GAT', 'GGC', 'TGT', 'AGT', 'GTT', 'GGG', 'GCT', 'GGA', 'CGT'], 'GGC': ['GGT', 'GCC', 'GGC', 'GAC', 'GGA', 'CGC', 'GTC', 'TGC', 'GGG', 'AGC'], 'GGG': ['GGT', 'GGC', 'GCG', 'GTG', 'GGA', 'CGG', 'AGG', 'GGG', 'GAG', 'TGG']}\n"
     ]
    }
   ],
   "source": [
    "voc_neigh = voc.copy()\n",
    "for w in voc_neigh:\n",
    "    voc_neigh[w] = build_1_neighborhood(w)\n",
    "print(voc_neigh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-13T11:58:56.930Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_1_hamming_embedding(x, length, voc_neigh):\n",
    "    st = STree.STree(x)\n",
    "    enc = np.zeros(len(voc_neigh))\n",
    "    i = 0\n",
    "    for w in voc_neigh.keys():\n",
    "        nset = voc_neigh[w]\n",
    "        enc[i] = sum([len(st.find_all(n)) for n in nset]) # all 1-Hamming matches of w in s0\n",
    "        i+=1\n",
    "    return enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-13T11:58:56.932Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([21., 18., 17., 19., 13.,  9., 16., 16., 19., 13., 18., 11., 20.,\n",
       "       18., 19., 14., 15.,  8., 10., 14., 10., 12., 14., 12., 15., 11.,\n",
       "       13., 14., 17., 15., 15., 18., 17., 13., 18., 22., 12., 15., 12.,\n",
       "       16., 17., 14., 17., 12., 18.,  9., 16., 15., 23., 16., 20., 16.,\n",
       "       12., 12., 12., 20., 19., 17., 13., 20., 19., 13., 19., 22.])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "letters = 'ATCG'\n",
    "length = 3\n",
    "voc = build_voc(letters, length)\n",
    "voc_neigh = voc.copy()\n",
    "for w in voc_neigh:\n",
    "    voc_neigh[w] = build_1_neighborhood(w)\n",
    "\n",
    "compute_1_hamming_embedding(s0, length, voc_neigh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-13T11:58:56.933Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11.,  7.,  8.,  6.,  5.,  6.,  6.,  3.,  9.,  5.,  8.,  3.,  6.,\n",
       "        4.,  8.,  3.,  6.,  2.,  2.,  3.,  4.,  3.,  6.,  5.,  4.,  6.,\n",
       "        5.,  3.,  5.,  4.,  3.,  4.,  7.,  5.,  9.,  4.,  4.,  3.,  5.,\n",
       "        7.,  8.,  4.,  5.,  3.,  3.,  3.,  4.,  1.,  9.,  6.,  6.,  8.,\n",
       "        2.,  6.,  5.,  5.,  8.,  7.,  7.,  5.,  7.,  4.,  4.,  5.,  5.,\n",
       "        2.,  5.,  3.,  0.,  3.,  3.,  2.,  4.,  2.,  2.,  1.,  5.,  0.,\n",
       "        6.,  3.,  2.,  1.,  4.,  3.,  2.,  2.,  6.,  5.,  5.,  2.,  5.,\n",
       "        2.,  7.,  5.,  4.,  8.,  8.,  3.,  4.,  6.,  3.,  3.,  6.,  5.,\n",
       "        3.,  3.,  5.,  5.,  3.,  2.,  6.,  3.,  6.,  5.,  6.,  9.,  4.,\n",
       "        2.,  3.,  9.,  8.,  4.,  6.,  6.,  6.,  4.,  8.,  6.,  7.,  9.,\n",
       "        8.,  5.,  5.,  4.,  5.,  5.,  6.,  6.,  7.,  4.,  8.,  6.,  4.,\n",
       "        7.,  4.,  3.,  2.,  3.,  2.,  5.,  1.,  7.,  6.,  6.,  4.,  5.,\n",
       "        6.,  5.,  8.,  6.,  8.,  4.,  5.,  6.,  1.,  5.,  4.,  7.,  5.,\n",
       "        6.,  4.,  5.,  3.,  4.,  4.,  7.,  4.,  2.,  2., 10.,  1.,  4.,\n",
       "        3.,  4.,  6.,  4.,  4.,  5.,  4.,  5.,  4.,  5., 10.,  3.,  8.,\n",
       "        8.,  3.,  5.,  5.,  6.,  6.,  6.,  4.,  3.,  9.,  8., 10.,  7.,\n",
       "        3.,  2.,  2.,  5.,  2.,  5.,  1.,  7.,  6.,  3.,  2.,  4.,  7.,\n",
       "        4.,  9.,  6.,  6.,  7.,  6.,  9.,  4.,  4.,  6.,  6.,  7.,  4.,\n",
       "        6.,  5.,  8.,  3.,  5.,  7.,  9.,  6.,  6.,  7.,  4.,  3.,  4.,\n",
       "        8.,  5.,  5.,  5.,  7.,  7.,  5.,  5., 11.])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "letters = 'ATCG'\n",
    "length = 4\n",
    "voc = build_voc(letters, length)\n",
    "voc_neigh = voc.copy()\n",
    "for w in voc_neigh:\n",
    "    voc_neigh[w] = build_1_neighborhood(w)\n",
    "\n",
    "compute_1_hamming_embedding(s0, length, voc_neigh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the data matrices (Hamming 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-13T11:58:56.935Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary has size 4096\n"
     ]
    }
   ],
   "source": [
    "letters = 'ATCG'\n",
    "length = 6\n",
    "voc = build_voc(letters, length)\n",
    "voc_neigh = voc.copy()\n",
    "for w in voc_neigh:\n",
    "    voc_neigh[w] = build_1_neighborhood(w)\n",
    "    \n",
    "print('Vocabulary has size', len(voc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-13T11:58:56.937Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2000it [20:56,  1.80it/s]\n",
      "2000it [18:01,  1.82it/s]\n",
      "2000it [17:47,  1.73it/s]\n"
     ]
    }
   ],
   "source": [
    "for ind in range(3):\n",
    "    df = pd.read_csv('data/Xtr'+str(ind)+'.csv')\n",
    "    df_emb = pd.DataFrame(columns = [str(i) for i in range(len(voc))])\n",
    "    for _, r in tqdm.tqdm(df.iterrows()):\n",
    "        i = r['Id']\n",
    "        seq = r['seq']\n",
    "        enc = compute_1_hamming_embedding(seq, length, voc_neigh)\n",
    "        df_emb.loc[i] = enc\n",
    "    df_emb.to_csv('data/'\n",
    "              + 'Xtr' +str(ind) + '_spectr'+str(length)+'_hamming1'+'.csv', header = False, index = False, sep=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-13T11:58:56.939Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [08:28,  1.98it/s]\n",
      "1000it [08:46,  1.99it/s]\n",
      "1000it [08:41,  2.00it/s]\n"
     ]
    }
   ],
   "source": [
    "for ind in range(3):\n",
    "    df = pd.read_csv('data/Xte'+str(ind)+'.csv')\n",
    "    df_emb = pd.DataFrame(columns = [str(i) for i in range(len(voc))])\n",
    "    for _, r in tqdm.tqdm(df.iterrows()):\n",
    "        i = r['Id']\n",
    "        seq = r['seq']\n",
    "        enc = compute_1_hamming_embedding(seq, length, voc_neigh)\n",
    "        df_emb.loc[i] = enc\n",
    "    df_emb.to_csv('data/'\n",
    "              + 'Xte' +str(ind) + '_spectr'+str(length)+'_hamming1'+'.csv', header = False, index = False, sep=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenate some embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_suffix = 'spectr6'\n",
    "second_suffix = 'spectr3_hamming1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 4096)\n",
      "(2000, 64)\n",
      "(2000, 4160)\n",
      "(2000, 4096)\n",
      "(2000, 64)\n",
      "(2000, 4160)\n",
      "(2000, 4096)\n",
      "(2000, 64)\n",
      "(2000, 4160)\n"
     ]
    }
   ],
   "source": [
    "for ind in range(3):\n",
    "    df1 = pd.read_csv('data/Xtr'+str(ind)+'_'+first_suffix+'.csv', header = None, sep=\" \")\n",
    "    print(df1.shape)\n",
    "    df2 = pd.read_csv('data/Xtr'+str(ind)+'_'+second_suffix+'.csv', header = None, sep=\" \")\n",
    "    print(df2.shape)\n",
    "    df_emb = pd.concat([df1, df2], axis=1, join='inner')\n",
    "    print(df_emb.shape)\n",
    "    df_emb.to_csv('data/'\n",
    "              + 'Xtr' + str(ind) + '_cat' + first_suffix + '-' \n",
    "              + second_suffix +'.csv', header = False, index = False, sep=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 4096)\n",
      "(1000, 64)\n",
      "(1000, 4160)\n",
      "(1000, 4096)\n",
      "(1000, 64)\n",
      "(1000, 4160)\n",
      "(1000, 4096)\n",
      "(1000, 64)\n",
      "(1000, 4160)\n"
     ]
    }
   ],
   "source": [
    "for ind in range(3):\n",
    "    df1 = pd.read_csv('data/Xte'+str(ind)+'_'+first_suffix+'.csv', header = None, sep=\" \")\n",
    "    print(df1.shape)\n",
    "    df2 = pd.read_csv('data/Xte'+str(ind)+'_'+second_suffix+'.csv', header = None, sep=\" \")\n",
    "    print(df2.shape)\n",
    "    df_emb = pd.concat([df1, df2], axis=1, join='inner')\n",
    "    print(df_emb.shape)\n",
    "    df_emb.to_csv('data/'\n",
    "              + 'Xte' + str(ind) + '_cat' + first_suffix + '-' \n",
    "              + second_suffix +'.csv', header = False, index = False, sep=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
