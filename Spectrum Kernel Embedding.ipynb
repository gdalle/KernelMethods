{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('kernel-methods-for-machine-learning-2018-2019/Xtr0.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>GGAGAATCATTTGAACCCGGGAGGTGGAGGTTGCCGTGAGCTGAGA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ACCCTGCCTACACCGCGGCGGGGACAGGTGGAGGTTTCAACCCCTG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>TGCAAATCTGTAAGCATTTCTCAGGCAATGAATTATGTCAACACAA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>GCGGGACGTGGGCGTCGAGGGTAAGGATATCTGCAGAAGTACTGTC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>GGAGAATAGCATGTATCCGAGAGGTGGAGCTGGCAGTGAGCCGAGA...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id                                                seq\n",
       "0   0  GGAGAATCATTTGAACCCGGGAGGTGGAGGTTGCCGTGAGCTGAGA...\n",
       "1   1  ACCCTGCCTACACCGCGGCGGGGACAGGTGGAGGTTTCAACCCCTG...\n",
       "2   2  TGCAAATCTGTAAGCATTTCTCAGGCAATGAATTATGTCAACACAA...\n",
       "3   3  GCGGGACGTGGGCGTCGAGGGTAAGGATATCTGCAGAAGTACTGTC...\n",
       "4   4  GGAGAATAGCATGTATCCGAGAGGTGGAGCTGGCAGTGAGCCGAGA..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All sequences is this set have length 101."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters = 'ATCG'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AAT': 1, 'AGA': 12, 'TAG': 19, 'ACG': 11, 'CTC': 38, 'GGC': 62, 'GCC': 58, 'ATT': 5, 'CAG': 35, 'GGT': 61, 'ATA': 4, 'GTC': 54, 'GCT': 57, 'GTT': 53, 'GGA': 60, 'ATG': 7, 'CTG': 39, 'TTA': 20, 'AGG': 15, 'CAC': 34, 'CGC': 46, 'ACT': 9, 'TCA': 24, 'AGT': 13, 'CCG': 43, 'TGA': 28, 'CCC': 42, 'TAC': 18, 'CCA': 40, 'TGG': 31, 'TCT': 25, 'TCC': 26, 'GTA': 52, 'CTT': 37, 'TTC': 22, 'ACA': 8, 'CGT': 45, 'AGC': 14, 'TGT': 29, 'GAG': 51, 'TTG': 23, 'GAT': 49, 'GCA': 56, 'GAC': 50, 'TCG': 27, 'AAA': 0, 'TTT': 21, 'CGA': 44, 'ATC': 6, 'CCT': 41, 'TAT': 17, 'CAA': 32, 'CGG': 47, 'ACC': 10, 'GTG': 55, 'TAA': 16, 'TGC': 30, 'CTA': 36, 'AAG': 3, 'GGG': 63, 'CAT': 33, 'AAC': 2, 'GCG': 59, 'GAA': 48}\n"
     ]
    }
   ],
   "source": [
    "def build_voc(letters, length):\n",
    "    vocl = [''.join(x) for x in itertools.product(letters, repeat=length)]\n",
    "    voc = {}\n",
    "    i = 0\n",
    "    for v in vocl:\n",
    "        voc[v] = i\n",
    "        i+=1\n",
    "    return voc\n",
    "voc = build_voc(letters, length)\n",
    "print(voc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\Phi_u(x)$ is the number of occurrences of u in x (without gaps) : *spectrum kernel* (Leslie et al., 2002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def substrings(x, length):\n",
    "    n = len(x)\n",
    "    sub = []\n",
    "    assert n>=length, 'seq too small'\n",
    "    for i in range(n-length+1):\n",
    "        curr = x[i:i+length]\n",
    "        sub.append(curr)\n",
    "    return sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GGA', 'GAG', 'AGA', 'GAA', 'AAT', 'ATC', 'TCA', 'CAT', 'ATT', 'TTT', 'TTG', 'TGA', 'GAA', 'AAC', 'ACC', 'CCC', 'CCG', 'CGG', 'GGG', 'GGA', 'GAG', 'AGG', 'GGT', 'GTG', 'TGG', 'GGA', 'GAG', 'AGG', 'GGT', 'GTT', 'TTG', 'TGC', 'GCC', 'CCG', 'CGT', 'GTG', 'TGA', 'GAG', 'AGC', 'GCT', 'CTG', 'TGA', 'GAG', 'AGA', 'GAT', 'ATT', 'TTG', 'TGC', 'GCG', 'CGC', 'GCC', 'CCA', 'CAT', 'ATT', 'TTG', 'TGC', 'GCA', 'CAC', 'ACT', 'CTC', 'TCC', 'CCA', 'CAG', 'AGC', 'GCC', 'CCT', 'CTG', 'TGG', 'GGG', 'GGC', 'GCA', 'CAA', 'AAC', 'ACA', 'CAA', 'AAG', 'AGA', 'GAG', 'AGC', 'GCA', 'CAA', 'AAA', 'AAA', 'AAC', 'ACT', 'CTC', 'TCT', 'CTG', 'TGT', 'GTC', 'TCT', 'CTC', 'TCA', 'CAC', 'ACA', 'CAA', 'AAA', 'AAA', 'AAC']\n"
     ]
    }
   ],
   "source": [
    "x = df['seq'][0]\n",
    "sub = substrings(x, 3)\n",
    "print(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GGAGAATCATTTGAACCCGGGAGGTGGAGGTTGCCGTGAGCTGAGATTGCGCCATTGCACTCCAGCCTGGGCAACAAGAGCAAAACTCTGTCTCACAAAAC'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we reduce to get the feature vector. Let $\\Phi_u(x)$ denote the number of occurrences of $u$ in $x$. The\n",
    "$k$-spectrum kernel is $K(x, x'):= \\sum_{u\\in A^k} \\Phi_u(x) \\Phi_u(x')$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It corresponds to a linear kernel over the feature space. So we may store all sequences in the feature space of all length 3 subsequences. The features will be sparse: at most $|x|-k+1$ non zero features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(sub, voc):\n",
    "    enc = np.zeros(len(voc))\n",
    "    for s in sub:\n",
    "        i = voc[s]\n",
    "        enc[i] += 1\n",
    "    return enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = encode(sub, voc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4. 1. 4. 1. 0. 3. 1. 0. 2. 2. 1. 0. 3. 0. 3. 2. 0. 0. 0. 0. 0. 1. 0. 4.\n",
      " 2. 2. 1. 0. 3. 1. 3. 2. 4. 2. 2. 1. 0. 0. 3. 3. 2. 1. 1. 2. 0. 1. 1. 1.\n",
      " 2. 1. 0. 6. 0. 1. 1. 2. 3. 1. 3. 1. 3. 2. 1. 2.]\n"
     ]
    }
   ],
   "source": [
    "print(encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the embedded data matrices (exact matching)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary has size 256\n"
     ]
    }
   ],
   "source": [
    "letters = 'ATCG'\n",
    "length = 4\n",
    "voc = build_voc(letters, length)\n",
    "print('Vocabulary has size', len(voc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2000it [00:04, 446.81it/s]\n",
      "2000it [00:03, 543.79it/s]\n",
      "2000it [00:03, 546.16it/s]\n"
     ]
    }
   ],
   "source": [
    "for ind in range(3):\n",
    "    df = pd.read_csv('kernel-methods-for-machine-learning-2018-2019/Xtr'+str(ind)+'.csv')\n",
    "    df_emb = pd.DataFrame(columns = [str(i) for i in range(len(voc))])\n",
    "    for _, r in tqdm.tqdm(df.iterrows()):\n",
    "        i = r['Id']\n",
    "        seq = r['seq']\n",
    "        enc = encode(substrings(seq, length), voc)\n",
    "        df_emb.loc[i] = enc\n",
    "    df_emb.to_csv('kernel-methods-for-machine-learning-2018-2019/'\n",
    "              + 'Xtr' +str(ind) + '_spectr'+str(length)+'.csv', header = False, index = False, sep=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [00:01, 665.74it/s]\n",
      "1000it [00:01, 682.00it/s]\n",
      "1000it [00:01, 665.64it/s]\n"
     ]
    }
   ],
   "source": [
    "for ind in range(3):\n",
    "    df = pd.read_csv('kernel-methods-for-machine-learning-2018-2019/Xte'+str(ind)+'.csv')\n",
    "    df_emb = pd.DataFrame(columns = [str(i) for i in range(len(voc))])\n",
    "    for _, r in tqdm.tqdm(df.iterrows()):\n",
    "        i = r['Id']\n",
    "        seq = r['seq']\n",
    "        enc = encode(substrings(seq, length), voc)\n",
    "        df_emb.loc[i] = enc\n",
    "    df_emb.to_csv('kernel-methods-for-machine-learning-2018-2019/'\n",
    "              + 'Xte' +str(ind) + '_spectr'+str(length)+'.csv', header = False, index = False, sep=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use suffix tree for mismatches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building suffix tree using Ukkonen's algorithm (external lib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'suffix_trees'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-2675ebb80954>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msuffix_trees\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSTree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: No module named 'suffix_trees'"
     ]
    }
   ],
   "source": [
    "from suffix_trees import STree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = 'BANANA' # has 6 suffixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = STree.STree(\"BANANA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3]"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.find_all('AN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters = 'ATCG'\n",
    "length = 3\n",
    "voc = build_voc(letters, length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "s0 = df['seq'][0]\n",
    "w = 'AAG'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "st0 = STree.STree(s0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build words at 1 Hamming distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_1_neighborhood(w):\n",
    "    nset = []\n",
    "    for i in range(len(w)):\n",
    "        for j in letters:\n",
    "            nset.append(w[:i]+j+w[i+1:])\n",
    "\n",
    "    nset = list(set(nset))\n",
    "    return nset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AAG', 'AAA', 'CAG', 'TAG', 'AAC', 'ACG', 'GAG', 'ATG', 'AAT', 'AGG']\n"
     ]
    }
   ],
   "source": [
    "nset = build_1_neighborhood(w)\n",
    "print(nset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nset) # 3+3+3 + 1 exact matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([len(st0.find_all(n)) for n in nset]) # all 1-Hamming matches of w in s0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AAA': ['AAA', 'TAA', 'AAG', 'AGA', 'CAA', 'ATA', 'GAA', 'AAC', 'ACA', 'AAT'], 'AAT': ['TAT', 'ACT', 'AAA', 'AAG', 'GAT', 'AAC', 'ATT', 'AGT', 'AAT', 'CAT'], 'AAC': ['TAC', 'AAA', 'AAG', 'CAC', 'GAC', 'ACC', 'AGC', 'AAC', 'AAT', 'ATC'], 'AAG': ['AAG', 'AAA', 'CAG', 'TAG', 'AAC', 'ACG', 'GAG', 'ATG', 'AAT', 'AGG'], 'ATA': ['TTA', 'AAA', 'ATT', 'AGA', 'ATG', 'ATA', 'CTA', 'ACA', 'GTA', 'ATC'], 'ATT': ['ACT', 'GTT', 'CTT', 'ATA', 'ATT', 'ATG', 'AGT', 'AAT', 'TTT', 'ATC'], 'ATC': ['CTC', 'TTC', 'ACC', 'AGC', 'ATA', 'AAC', 'ATT', 'ATG', 'GTC', 'ATC'], 'ATG': ['ATC', 'AAG', 'GTG', 'AGG', 'TTG', 'ATA', 'ACG', 'ATT', 'ATG', 'CTG'], 'ACA': ['CCA', 'AAA', 'AGA', 'GCA', 'ATA', 'ACC', 'TCA', 'ACA', 'ACG', 'ACT'], 'ACT': ['AAT', 'TCT', 'GCT', 'ACC', 'CCT', 'ACA', 'ATT', 'ACG', 'AGT', 'ACT'], 'ACC': ['CCC', 'GCC', 'TCC', 'ACC', 'AGC', 'AAC', 'ACA', 'ACG', 'ACT', 'ATC'], 'ACG': ['AAG', 'CCG', 'ATG', 'ACC', 'ACA', 'ACG', 'ACT', 'TCG', 'GCG', 'AGG'], 'AGA': ['AAA', 'AGA', 'CGA', 'ATA', 'AGC', 'GGA', 'ACA', 'TGA', 'AGT', 'AGG'], 'AGT': ['ACT', 'TGT', 'AGA', 'CGT', 'AGC', 'ATT', 'AGT', 'AAT', 'GGT', 'AGG'], 'AGC': ['AGT', 'AGG', 'AGA', 'AGC', 'ACC', 'AAC', 'GGC', 'CGC', 'TGC', 'ATC'], 'AGG': ['AAG', 'GGG', 'AGA', 'ATG', 'AGC', 'TGG', 'ACG', 'CGG', 'AGT', 'AGG'], 'TAA': ['TAC', 'TTA', 'TAT', 'AAA', 'TAA', 'CAA', 'TAG', 'GAA', 'TCA', 'TGA'], 'TAT': ['TAC', 'TAT', 'TAA', 'TGT', 'TAG', 'TCT', 'GAT', 'AAT', 'CAT', 'TTT'], 'TAC': ['TAC', 'TAT', 'TAA', 'CAC', 'TTC', 'TCC', 'TAG', 'GAC', 'AAC', 'TGC'], 'TAG': ['TAC', 'TAT', 'AAG', 'TAA', 'CAG', 'TAG', 'TTG', 'TGG', 'GAG', 'TCG'], 'TTA': ['TTA', 'TAA', 'TTC', 'TGA', 'TTG', 'ATA', 'TCA', 'CTA', 'GTA', 'TTT'], 'TTT': ['TAT', 'TTA', 'GTT', 'TTC', 'TGT', 'TCT', 'TTG', 'CTT', 'ATT', 'TTT'], 'TTC': ['TAC', 'TTA', 'CTC', 'TTC', 'TCC', 'TTG', 'TTT', 'TGC', 'GTC', 'ATC'], 'TTG': ['TTA', 'GTG', 'TTT', 'TTC', 'TAG', 'TTG', 'TGG', 'ATG', 'TCG', 'CTG'], 'TCA': ['CCA', 'TTA', 'TAA', 'TCC', 'TCT', 'GCA', 'TCA', 'ACA', 'TGA', 'TCG'], 'TCT': ['TCG', 'TAT', 'TGT', 'TCC', 'TCT', 'GCT', 'CCT', 'TCA', 'ACT', 'TTT'], 'TCC': ['TAC', 'CCC', 'TTC', 'GCC', 'TCC', 'TCT', 'ACC', 'TCA', 'TGC', 'TCG'], 'TCG': ['CCG', 'TAG', 'TCC', 'TCT', 'TTG', 'TGG', 'TCA', 'ACG', 'TCG', 'GCG'], 'TGA': ['TTA', 'TAA', 'TGT', 'AGA', 'CGA', 'TGG', 'GGA', 'TCA', 'TGA', 'TGC'], 'TGT': ['TAT', 'TGC', 'TGT', 'CGT', 'TCT', 'TGG', 'TGA', 'AGT', 'TTT', 'GGT'], 'TGC': ['TAC', 'TTC', 'TGT', 'TCC', 'AGC', 'TGG', 'GGC', 'CGC', 'TGA', 'TGC'], 'TGG': ['GGG', 'TGT', 'TAG', 'TGA', 'TTG', 'TGG', 'CGG', 'TGC', 'TCG', 'AGG'], 'CAA': ['CCA', 'AAA', 'TAA', 'CAC', 'CAG', 'CGA', 'CAA', 'GAA', 'CTA', 'CAT'], 'CAT': ['TAT', 'CAC', 'CAG', 'CGT', 'CAA', 'GAT', 'CTT', 'CCT', 'AAT', 'CAT'], 'CAC': ['TAC', 'CCC', 'CTC', 'CAC', 'CAG', 'CAA', 'GAC', 'AAC', 'CGC', 'CAT'], 'CAG': ['AAG', 'CAG', 'CAC', 'CCG', 'TAG', 'CAA', 'GAG', 'CGG', 'CAT', 'CTG'], 'CTA': ['CCA', 'TTA', 'CTC', 'CGA', 'CAA', 'ATA', 'CTT', 'CTA', 'GTA', 'CTG'], 'CTT': ['CTC', 'GTT', 'CGT', 'CTT', 'CCT', 'CTA', 'ATT', 'CAT', 'TTT', 'CTG'], 'CTC': ['CCC', 'CTC', 'CAC', 'TTC', 'CTG', 'CTT', 'CTA', 'CGC', 'GTC', 'ATC'], 'CTG': ['CGG', 'GTG', 'CTC', 'CAG', 'CCG', 'TTG', 'CTT', 'CTA', 'ATG', 'CTG'], 'CCA': ['CCA', 'CCC', 'CCG', 'CGA', 'CAA', 'GCA', 'CCT', 'TCA', 'ACA', 'CTA'], 'CCT': ['CCA', 'CCC', 'CCG', 'CGT', 'TCT', 'GCT', 'CTT', 'CCT', 'ACT', 'CAT'], 'CCC': ['CCC', 'CCA', 'CTC', 'CAC', 'GCC', 'CCG', 'TCC', 'ACC', 'CCT', 'CGC'], 'CCG': ['CCA', 'CCC', 'CGG', 'CAG', 'CCG', 'CCT', 'ACG', 'TCG', 'GCG', 'CTG'], 'CGA': ['CCA', 'CGG', 'AGA', 'CGA', 'CAA', 'CGT', 'GGA', 'CTA', 'CGC', 'TGA'], 'CGT': ['TGT', 'CGA', 'CGT', 'CTT', 'CCT', 'CGC', 'CGG', 'AGT', 'CAT', 'GGT'], 'CGC': ['CCC', 'CTC', 'CAC', 'CGA', 'CGT', 'AGC', 'GGC', 'CGC', 'CGG', 'TGC'], 'CGG': ['GGG', 'CAG', 'CCG', 'CGA', 'CGT', 'TGG', 'CGC', 'CGG', 'CTG', 'AGG'], 'GAA': ['AAA', 'TAA', 'CAA', 'GAC', 'GCA', 'GAT', 'GAA', 'GGA', 'GAG', 'GTA'], 'GAT': ['TAT', 'GTT', 'GAC', 'GCT', 'GAT', 'GAA', 'GAG', 'AAT', 'CAT', 'GGT'], 'GAC': ['TAC', 'CAC', 'GCC', 'GAC', 'GAT', 'GAA', 'AAC', 'GGC', 'GAG', 'GTC'], 'GAG': ['AAG', 'GTG', 'CAG', 'GGG', 'TAG', 'GAC', 'GAT', 'GAA', 'GAG', 'GCG'], 'GTA': ['TTA', 'GTG', 'GTT', 'GCA', 'ATA', 'GAA', 'GGA', 'CTA', 'GTA', 'GTC'], 'GTT': ['GTC', 'GTG', 'GTT', 'GCT', 'CTT', 'GAT', 'ATT', 'GTA', 'TTT', 'GGT'], 'GTC': ['GTG', 'CTC', 'TTC', 'GCC', 'GTT', 'GAC', 'GGC', 'GTA', 'GTC', 'ATC'], 'GTG': ['GTC', 'GTG', 'GGG', 'GTT', 'TTG', 'GAG', 'ATG', 'GTA', 'GCG', 'CTG'], 'GCA': ['CCA', 'GCC', 'GCA', 'GCT', 'GAA', 'TCA', 'ACA', 'GGA', 'GTA', 'GCG'], 'GCT': ['GTT', 'GCC', 'TCT', 'GCA', 'GCT', 'GAT', 'CCT', 'ACT', 'GGT', 'GCG'], 'GCC': ['CCC', 'GCC', 'TCC', 'GAC', 'GCA', 'GCT', 'ACC', 'GGC', 'GTC', 'GCG'], 'GCG': ['GTG', 'GGG', 'GCC', 'CCG', 'GCA', 'GCT', 'GAG', 'ACG', 'TCG', 'GCG'], 'GGA': ['GGG', 'AGA', 'CGA', 'GCA', 'GAA', 'GGC', 'GGA', 'TGA', 'GTA', 'GGT'], 'GGT': ['GGG', 'GTT', 'TGT', 'CGT', 'GCT', 'GAT', 'GGC', 'GGA', 'AGT', 'GGT'], 'GGC': ['GGG', 'GCC', 'GAC', 'AGC', 'GGC', 'GGA', 'CGC', 'TGC', 'GTC', 'GGT'], 'GGG': ['GTG', 'GGG', 'TGG', 'GGC', 'GGA', 'GAG', 'CGG', 'GGT', 'GCG', 'AGG']}\n"
     ]
    }
   ],
   "source": [
    "voc_neigh = voc.copy()\n",
    "for w in voc_neigh:\n",
    "    voc_neigh[w] = build_1_neighborhood(w)\n",
    "print(voc_neigh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_1_hamming_embedding(x, length, voc_neigh):\n",
    "    st = STree.STree(x)\n",
    "    enc = np.zeros(len(voc_neigh))\n",
    "    i = 0\n",
    "    for w in voc_neigh.keys():\n",
    "        nset = voc_neigh[w]\n",
    "        enc[i] = sum([len(st.find_all(n)) for n in nset]) # all 1-Hamming matches of w in s0\n",
    "        i+=1\n",
    "    return enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7.,  5., 12.,  9.,  2.,  3., 10., 16., 11., 15., 20., 15.,  7.,\n",
       "       10., 21., 14.,  6.,  3., 11.,  8.,  4.,  6., 10., 16., 10., 13.,\n",
       "       27., 14., 12., 14., 24., 17., 13., 10., 18., 22., 16., 14., 24.,\n",
       "       19., 23., 24., 36., 32., 13., 13., 27., 29.,  6., 12., 17., 12.,\n",
       "        6., 13., 20., 16., 20., 22., 35., 22., 15., 18., 27., 24.])"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "letters = 'ATCG'\n",
    "length = 3\n",
    "voc = build_voc(letters, length)\n",
    "voc_neigh = voc.copy()\n",
    "for w in voc_neigh:\n",
    "    voc_neigh[w] = build_1_neighborhood(w)\n",
    "\n",
    "compute_1_hamming_embedding(s0, length, voc_neigh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.,  3.,  2.,  3.,  1.,  1.,  3.,  3.,  0.,  2.,  7.,  3.,  2.,\n",
       "        4.,  4.,  5.,  0.,  0.,  1.,  1.,  1.,  2.,  2.,  1.,  1.,  2.,\n",
       "        6.,  1.,  1.,  2.,  8.,  5.,  2.,  1.,  4.,  4.,  0.,  2.,  4.,\n",
       "        9.,  8.,  6., 10.,  7.,  1.,  2.,  8.,  4.,  1.,  1.,  4.,  1.,\n",
       "        0.,  3.,  5.,  2.,  2.,  8., 10.,  4.,  3.,  5.,  9.,  6.,  2.,\n",
       "        1.,  1.,  2.,  0.,  1.,  1.,  1.,  1.,  2.,  5.,  3.,  0.,  2.,\n",
       "        3.,  3.,  2.,  0.,  2.,  0.,  1.,  0.,  4.,  1.,  2.,  5.,  4.,\n",
       "        5.,  2.,  3.,  7.,  4.,  2.,  2.,  4.,  5.,  2.,  2.,  3.,  9.,\n",
       "        8.,  5., 11.,  8.,  2.,  3.,  5.,  4.,  3.,  4.,  5.,  3.,  1.,\n",
       "        5.,  5.,  6.,  6., 11., 14.,  5.,  4.,  6., 11.,  8.,  4.,  2.,\n",
       "        6.,  7.,  1.,  2.,  2.,  5.,  6.,  7.,  6.,  5.,  4.,  4., 10.,\n",
       "       10.,  3.,  3.,  5.,  5.,  0.,  2.,  5.,  7.,  5.,  5., 11.,  6.,\n",
       "       10.,  9., 11., 13., 11.,  6.,  8., 10.,  8.,  4., 10., 11., 10.,\n",
       "       12., 19., 15.,  8.,  6., 12., 18.,  3.,  4.,  5.,  4.,  1.,  3.,\n",
       "        2.,  7.,  8.,  8., 12.,  8.,  4.,  8., 14.,  9.,  2.,  2.,  2.,\n",
       "        3.,  0.,  2.,  3.,  7.,  3.,  3., 10.,  3.,  1.,  0.,  6.,  5.,\n",
       "        1.,  0.,  3.,  2.,  2.,  2.,  5.,  7.,  5.,  4., 11.,  2.,  2.,\n",
       "        3., 10.,  7.,  4.,  1.,  8.,  9.,  6.,  6., 10., 14.,  9., 10.,\n",
       "       16., 14.,  5.,  2., 11.,  9.,  2.,  3.,  6.,  4.,  4.,  5., 11.,\n",
       "        7.,  7., 10., 16., 11.,  4.,  8., 11.,  7.])"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "letters = 'ATCG'\n",
    "length = 4\n",
    "voc = build_voc(letters, length)\n",
    "voc_neigh = voc.copy()\n",
    "for w in voc_neigh:\n",
    "    voc_neigh[w] = build_1_neighborhood(w)\n",
    "\n",
    "compute_1_hamming_embedding(s0, length, voc_neigh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the data matrices (Hamming 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary has size 64\n"
     ]
    }
   ],
   "source": [
    "letters = 'ATCG'\n",
    "length = 3\n",
    "voc = build_voc(letters, length)\n",
    "voc_neigh = voc.copy()\n",
    "for w in voc_neigh:\n",
    "    voc_neigh[w] = build_1_neighborhood(w)\n",
    "    \n",
    "print('Vocabulary has size', len(voc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2000it [00:39, 50.46it/s]\n",
      "2000it [01:18, 19.69it/s]\n",
      "2000it [01:13, 21.24it/s]\n"
     ]
    }
   ],
   "source": [
    "for ind in range(3):\n",
    "    df = pd.read_csv('kernel-methods-for-machine-learning-2018-2019/Xtr'+str(ind)+'.csv')\n",
    "    df_emb = pd.DataFrame(columns = [str(i) for i in range(len(voc))])\n",
    "    for _, r in tqdm.tqdm(df.iterrows()):\n",
    "        i = r['Id']\n",
    "        seq = r['seq']\n",
    "        enc = compute_1_hamming_embedding(seq, length, voc_neigh)\n",
    "        df_emb.loc[i] = enc\n",
    "    df_emb.to_csv('kernel-methods-for-machine-learning-2018-2019/'\n",
    "              + 'Xtr' +str(ind) + '_spectr'+str(length)+'_hamming1'+'.csv', header = False, index = False, sep=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [00:35, 28.00it/s]\n",
      "1000it [00:14, 66.74it/s]\n",
      "1000it [00:18, 54.37it/s]\n"
     ]
    }
   ],
   "source": [
    "for ind in range(3):\n",
    "    df = pd.read_csv('kernel-methods-for-machine-learning-2018-2019/Xte'+str(ind)+'.csv')\n",
    "    df_emb = pd.DataFrame(columns = [str(i) for i in range(len(voc))])\n",
    "    for _, r in tqdm.tqdm(df.iterrows()):\n",
    "        i = r['Id']\n",
    "        seq = r['seq']\n",
    "        enc = compute_1_hamming_embedding(seq, length, voc_neigh)\n",
    "        df_emb.loc[i] = enc\n",
    "    df_emb.to_csv('kernel-methods-for-machine-learning-2018-2019/'\n",
    "              + 'Xte' +str(ind) + '_spectr'+str(length)+'_hamming1'+'.csv', header = False, index = False, sep=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
