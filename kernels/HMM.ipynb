{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T21:23:25.130850Z",
     "start_time": "2019-03-13T21:23:14.793309Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T21:23:26.222141Z",
     "start_time": "2019-03-13T21:23:26.215785Z"
    }
   },
   "outputs": [],
   "source": [
    "def loglikelihood(y, A, B, pi):\n",
    "    T = len(y)\n",
    "    n_s = A.shape[0]\n",
    "    \n",
    "    norm = np.empty(T)\n",
    "\n",
    "    alpha = np.empty((T, n_s))\n",
    "    alpha[0] = pi * B[:, y[0]]\n",
    "    norm[0] = 1/alpha[0].sum()\n",
    "    for t in range(T-1):\n",
    "        alpha[t+1] = B[:, y[t+1]] * A.T.dot(alpha[t])\n",
    "        norm[t+1] = 1/alpha[t+1].sum()\n",
    "        alpha[t+1] *= norm[t+1]\n",
    "\n",
    "    loglike = alpha[T-1].sum() - np.log(norm).sum()\n",
    "    return loglike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T21:23:27.048286Z",
     "start_time": "2019-03-13T21:23:27.039463Z"
    }
   },
   "outputs": [],
   "source": [
    "def forward_backward(y, A, B, pi):\n",
    "    T = len(y)\n",
    "    n_s = A.shape[0]\n",
    "    \n",
    "    norm = np.empty(T)\n",
    "\n",
    "    alpha = np.empty((T, n_s))\n",
    "    alpha[0] = pi * B[:, y[0]]\n",
    "    norm[0] = 1/alpha[0].sum()\n",
    "    alpha[0] *= norm[0]\n",
    "    for t in range(T-1):\n",
    "        alpha[t+1] = B[:, y[t+1]] * A.T.dot(alpha[t])\n",
    "        norm[t+1] = 1/alpha[t+1].sum()\n",
    "        alpha[t+1] *= norm[t+1]\n",
    "\n",
    "    beta = np.empty((T, n_s))\n",
    "    beta[T-1] = norm[T-1] * 1\n",
    "    beta[T-1] *= norm[T-1]\n",
    "    for t in range(T-2, -1, -1):\n",
    "        beta[t] = A.dot(beta[t+1] * B[:, y[t+1]])\n",
    "        beta[t] *= norm[t]\n",
    "\n",
    "    return alpha, beta, norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T21:23:27.533617Z",
     "start_time": "2019-03-13T21:23:27.522065Z"
    }
   },
   "outputs": [],
   "source": [
    "def update(y, A, B, pi, alpha, beta, norm):\n",
    "    T = len(y)\n",
    "    n_s = A.shape[0]\n",
    "    n_o = B.shape[1]\n",
    "    \n",
    "    new_pi = np.empty(n_s)\n",
    "    new_A = np.empty((n_s, n_s))\n",
    "    new_B = np.empty((n_s, n_o))\n",
    "    \n",
    "    for i in range(n_s):\n",
    "        new_pi[i] = alpha[0, i] * beta[0, i] / alpha[0].dot(beta[0])\n",
    "    \n",
    "    for i in range(n_s):\n",
    "        for j in range(n_s):\n",
    "            new_A[i, j] = sum(\n",
    "                [alpha[t, i] * A[i, j] * B[j, y[t+1]] * beta[t+1, j] for t in range(T-1)]\n",
    "            ) / sum(\n",
    "                [alpha[t, i] * beta[t, i] / norm[t] for t in range(T-1)]\n",
    "            )\n",
    "    for j in range(n_s):\n",
    "        for k in range(n_o):\n",
    "            new_B[j, k] = sum(\n",
    "                [alpha[t, j] * beta[t, j] / norm[t] for t in range(T) if y[t] == k]\n",
    "            ) / sum(\n",
    "                [alpha[t, j] * beta[t, j] / norm[t] for t in range(T)]\n",
    "            )\n",
    "            \n",
    "    return new_A, new_B, new_pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T21:23:27.849275Z",
     "start_time": "2019-03-13T21:23:27.843717Z"
    }
   },
   "outputs": [],
   "source": [
    "def baum_welch_step(y, A, B, pi):\n",
    "    alpha, beta, norm = forward_backward(y, A, B, pi)\n",
    "    return update(y, A, B, pi, alpha, beta, norm)\n",
    "\n",
    "def baum_welch(y, A0, B0, pi0, iterations=100):\n",
    "    A, B, pi = A0, B0, pi0\n",
    "    for it in tqdm.trange(iterations):\n",
    "        A, B, pi = baum_welch_step(y, A, B, pi)\n",
    "    return A, B, pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T21:23:32.520418Z",
     "start_time": "2019-03-13T21:23:32.505621Z"
    }
   },
   "outputs": [],
   "source": [
    "def baum_welch_step_dataset2(dataset, A, B, pi):\n",
    "    \n",
    "    n_s = A.shape[0]\n",
    "    n_o = B.shape[1]\n",
    "    \n",
    "    new_A_num = np.zeros((n_s, n_s))\n",
    "    new_A_den = np.zeros((n_s, n_s))\n",
    "    new_B_num = np.zeros((n_s, n_o))\n",
    "    new_B_den = np.zeros((n_s, n_o))\n",
    "    new_pi_num = np.zeros(n_s)\n",
    "    new_pi_den = np.zeros(n_s)\n",
    "    \n",
    "    for y in dataset:\n",
    "        T = len(y)\n",
    "        alpha, beta, norm = forward_backward(y, A, B, pi)\n",
    "        \n",
    "        for i in range(n_s):\n",
    "            new_pi_num[i] += alpha[t, i] * beta[t, i] / norm[t]\n",
    "            new_pi_den[i] += 1\n",
    "\n",
    "        for i in range(n_s):\n",
    "            for j in range(n_s):\n",
    "                new_A_num[i, j] += sum(\n",
    "                    [alpha[t, i] * A[i, j] * B[j, y[t+1]] * beta[t+1, j] for t in range(T-1)]\n",
    "                )\n",
    "                new_A_den[i, j] += sum(\n",
    "                    [alpha[t, i] * beta[t, i] / norm[t] for t in range(T-1)]\n",
    "                )\n",
    "        for j in range(n_s):\n",
    "            for k in range(n_o):\n",
    "                new_B_num[j, k] += sum(\n",
    "                    [alpha[t, j] * beta[t, j] / norm[t] for t in range(T-1) if y[t] == k]\n",
    "                )\n",
    "                new_B_den[j, k] += sum(\n",
    "                    [alpha[t, j] * beta[t, j] / norm[t] for t in range(T-1)]\n",
    "                )\n",
    "\n",
    "    return new_A_num/new_A_den, new_B_num/new_B_den, new_pi_num/new_pi_den\n",
    "\n",
    "def baum_welch_dataset2(dataset, A0, B0, pi0, iterations=100):\n",
    "    A, B, pi = A0, B0, pi0\n",
    "    for it in tqdm.trange(iterations):\n",
    "        A, B, pi = baum_welch_step_dataset2(dataset, A, B, pi)\n",
    "    return A, B, pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T21:23:33.104121Z",
     "start_time": "2019-03-13T21:23:33.093193Z"
    }
   },
   "outputs": [],
   "source": [
    "def baum_welch_step_dataset(dataset, A, B, pi):\n",
    "    \n",
    "    n_s = A.shape[0]\n",
    "    n_o = B.shape[1]\n",
    "    \n",
    "    new_A_num = np.zeros((n_s, n_s))\n",
    "    new_A_den = np.zeros((n_s, n_s))\n",
    "    new_B_num = np.zeros((n_s, n_o))\n",
    "    new_B_den = np.zeros((n_s, n_o))\n",
    "    new_pi_num = np.zeros(n_s)\n",
    "    new_pi_den = np.zeros(n_s)\n",
    "    \n",
    "    for y in dataset:\n",
    "        T = len(y)\n",
    "        alpha, beta, norm = forward_backward(y, A, B, pi)\n",
    "        \n",
    "        new_A_num += (\n",
    "            alpha[:-1, :, None] * A[None, :, :] * B[:, y[1:]].T[:, None, :] * beta[1:, None, :]\n",
    "        ).sum(axis=0)\n",
    "        new_A_den += (\n",
    "            alpha[:-1, :, None] * beta[:-1, :, None] / norm[:-1, None, None]\n",
    "        ).sum(axis=0)\n",
    "        \n",
    "        onehot_encoder = OneHotEncoder(sparse=False, categories=\"auto\")\n",
    "        y_binary = onehot_encoder.fit_transform(y[:, None]).astype(int)\n",
    "        new_B_num += (\n",
    "            y_binary[:-1, None, :] * alpha[:-1, :, None] * beta[:-1, :, None] / norm[:-1, None, None]\n",
    "        ).sum(axis=0)\n",
    "        new_B_den += (\n",
    "            alpha[:-1, :, None] * beta[:-1, :, None] / norm[:-1, None, None]\n",
    "        ).sum(axis=0)\n",
    "        \n",
    "        new_pi_num += alpha[0, :] * beta[0, :] / norm[0]\n",
    "        new_pi_den += 1\n",
    "\n",
    "    return new_A_num/new_A_den, new_B_num/new_B_den, new_pi_num/new_pi_den\n",
    "\n",
    "def baum_welch_dataset(dataset, A0, B0, pi0, iterations=100):\n",
    "    A, B, pi = A0, B0, pi0\n",
    "    for it in tqdm.trange(iterations):\n",
    "        A, B, pi = baum_welch_step_dataset(dataset, A, B, pi)\n",
    "    return A, B, pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T21:23:25.166847Z",
     "start_time": "2019-03-13T21:23:25.133584Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(63)\n",
    "\n",
    "states = np.arange(4)\n",
    "observations = np.arange(4)\n",
    "\n",
    "pi_th = np.random.random(4)\n",
    "pi_th /= pi_th.sum()\n",
    "\n",
    "A_th = np.random.random((4, 4))\n",
    "i_zero = [0, 0, 0, 1, 1, 1, 2, 2, 3, 3]\n",
    "j_zero = [0, 2, 3, 0, 1, 3, 1, 2, 1, 2]\n",
    "A_th[i_zero, j_zero] = 0\n",
    "A_th /= A_th.sum(axis=1)[:, None]\n",
    "\n",
    "B_th = np.random.random((4, 4))\n",
    "B_th /= B_th.sum(axis=1)[:, None]\n",
    "\n",
    "def generate(A, B, pi, T):\n",
    "    x = []\n",
    "    y = []\n",
    "    for t in range(T):\n",
    "        if t == 0:\n",
    "            x.append(np.random.choice(states, p=pi))\n",
    "        else:\n",
    "            x.append(np.random.choice(states, p=A[x[-1]]))\n",
    "        y.append(np.random.choice(observations, p=B[x[-1]]))\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    return x, y\n",
    "\n",
    "x1, y1 = generate(A_th, B_th, pi_th, 250)\n",
    "x2, y2 = generate(A_th, B_th, pi_th, 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T21:58:14.344945Z",
     "start_time": "2019-02-26T21:58:14.338858Z"
    }
   },
   "outputs": [],
   "source": [
    "def baum_welch_dna1(dataset, iterations=100):\n",
    "    np.random.seed(63)\n",
    "    A_guess = np.array([\n",
    "        [  0,   1,   0,   0,], # exon 1 => exon 2\n",
    "        [  0,   0,   1,   0,], # exon 2 => exon 3\n",
    "        [0.5,   0,   0, 0.5,], # exon 3 => exon 1 or intron\n",
    "        [0.5,   0,   0, 0.5,],\n",
    "    ])\n",
    "    A0 = np.random.random((4, 4)) * A_guess\n",
    "    A0 /= A0.sum(axis=1)[:, None]\n",
    "    \n",
    "    B0 = np.random.random((4, 4)) / 4\n",
    "    B0 /= B0.sum(axis=1)[:, None]\n",
    "    \n",
    "    pi0 = np.random.random(4)\n",
    "    pi0 /= pi0.sum()\n",
    "    \n",
    "    print(\"\\nInitial values\")\n",
    "    print(A0)\n",
    "    print(B0)\n",
    "    print(pi0)\n",
    "\n",
    "    A, B, pi = baum_welch_dataset(dataset, A0, B0, pi0, iterations)\n",
    "    \n",
    "    print(\"Estimation\")\n",
    "    print(A)\n",
    "    print(B)\n",
    "    print(pi)\n",
    "    \n",
    "    return A, B, pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T21:58:14.344945Z",
     "start_time": "2019-02-26T21:58:14.338858Z"
    }
   },
   "outputs": [],
   "source": [
    "def baum_welch_dna2(dataset, iterations=100):\n",
    "    np.random.seed(63)\n",
    "    A_guess = np.array([\n",
    "        [  0,   1,   0,   0,], # exon 1 => exon 2\n",
    "        [  0,   0,   1,   0,], # exon 2 => exon 3\n",
    "        [0.5,   0,   0, 0.5,], # exon 3 => exon 1 or intron\n",
    "        [0.5,   0,   0, 0.5,],\n",
    "    ])\n",
    "    A0 = np.random.random((4, 4)) * A_guess\n",
    "    A0 /= A0.sum(axis=1)[:, None]\n",
    "    \n",
    "    B0 = np.random.random((4, 4)) / 4\n",
    "    B0 /= B0.sum(axis=1)[:, None]\n",
    "    \n",
    "    pi0 = np.random.random(4)\n",
    "    pi0 /= pi0.sum()\n",
    "    \n",
    "    print(\"\\nInitial values\")\n",
    "    print(A0)\n",
    "    print(B0)\n",
    "    print(pi0)\n",
    "\n",
    "    A, B, pi = baum_welch_dataset(dataset, A0, B0, pi0, iterations)\n",
    "    \n",
    "    print(\"Estimation\")\n",
    "    print(A)\n",
    "    print(B)\n",
    "    print(pi)\n",
    "    \n",
    "    return A, B, pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T21:58:14.350875Z",
     "start_time": "2019-02-26T21:58:14.347036Z"
    }
   },
   "outputs": [],
   "source": [
    "def translate(dna_string):\n",
    "    dna_string = dna_string.replace(\"A\", \"0\")\n",
    "    dna_string = dna_string.replace(\"T\", \"1\")\n",
    "    dna_string = dna_string.replace(\"G\", \"2\")\n",
    "    dna_string = dna_string.replace(\"C\", \"3\")\n",
    "    seq = list(dna_string)\n",
    "    return np.array(seq).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T21:58:20.854058Z",
     "start_time": "2019-02-26T21:58:14.353181Z"
    }
   },
   "outputs": [],
   "source": [
    "n_samples = 10\n",
    "iterations = 100\n",
    "for d in range(3):\n",
    "    dataset_string = pd.read_csv(\"data/Xtr{}.csv\".format(d), index_col=0)\n",
    "    dataset = [\n",
    "        translate(dna_string)\n",
    "        for dna_string in dataset_string.values[:, 0]\n",
    "    ]\n",
    "    A, B, pi = baum_welch_dna(dataset[:n_samples], iterations)\n",
    "    pd.DataFrame(A).to_csv(\"HMMbis_{}_A.csv\".format(d))\n",
    "    pd.DataFrame(B).to_csv(\"HMMbis_{}_B.csv\".format(d))\n",
    "    pd.DataFrame(c).to_csv(\"HMMbis_{}_c.csv\".format(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T22:38:11.685946Z",
     "start_time": "2019-02-26T22:38:11.673635Z"
    }
   },
   "outputs": [],
   "source": [
    "def first_order_marginalized_count(y, A, B, pi):\n",
    "    alpha, beta, norm = forward_backward(y, A, B, pi)\n",
    "    onehot_encoder = OneHotEncoder(sparse=False, categories=\"auto\")\n",
    "    y_binary = onehot_encoder.fit_transform(y[:, None]).astype(int)\n",
    "    return (y_binary[:, :, None] * alpha[:, None, :]).mean(axis=0).flatten()\n",
    "\n",
    "def first_order_mc_features(dataset, A, B, pi):\n",
    "    return np.array([\n",
    "        marginalized_count(y, A, B, pi)\n",
    "        for y in dataset\n",
    "    ])\n",
    "\n",
    "def second_order_marginalized_count(y, A, B, pi):\n",
    "    alpha, beta, norm = forward_backward(y, A, B, pi)\n",
    "    ksi = alpha[:-1, :, None] * A[None, :, :] * B[:, y[1:]].T[:, None, :] * beta[1:, None, :]\n",
    "    onehot_encoder = OneHotEncoder(sparse=False, categories=\"auto\")\n",
    "    y_binary = onehot_encoder.fit_transform(y[:, None]).astype(int)\n",
    "    # axes : t, i1, k1, i2, k2\n",
    "    return (\n",
    "        y_binary[:-1, :, None, None, None] *\n",
    "        y_binary[1:, None, None, :, None] *\n",
    "        ksi[:, None, :, None, :]\n",
    "    ).mean(axis=0).flatten()\n",
    "\n",
    "def second_order_mc_features(dataset, A, B, pi):\n",
    "    return np.array([\n",
    "        second_order_marginalized_count(y, A, B, pi)\n",
    "        for y in dataset\n",
    "    ])\n",
    "\n",
    "def mc_features(dataset, A, B, pi, order):\n",
    "    if order == 1:\n",
    "        return first_order_mc_features(dataset, A, B, pi)\n",
    "    elif order == 2:\n",
    "        return second_order_mc_features(dataset, A, B, pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T22:38:49.865604Z",
     "start_time": "2019-02-26T22:38:12.298980Z"
    }
   },
   "outputs": [],
   "source": [
    "for d in tqdm.trange(3):\n",
    "    for order in [1, 2]:\n",
    "        A = np.array(pd.read_csv(\"data/HMM_{}_A.csv\".format(d), index_col=0))\n",
    "        B = np.array(pd.read_csv(\"data/HMM_{}_B.csv\".format(d), index_col=0))\n",
    "        pi = np.array(pd.read_csv(\"data/HMM_{}_pi.csv\".format(d), index_col=0))[:, 0]\n",
    "\n",
    "        train_string = pd.read_csv(\"data/Xtr{}.csv\".format(d), index_col=0)\n",
    "        train_num = [\n",
    "            translate(dna_string)\n",
    "            for dna_string in train_string.values[:, 0]\n",
    "        ]\n",
    "        Xtr = mc_features(train_num, A, B, pi, order)\n",
    "        pd.DataFrame(Xtr).to_csv(\"data/Xtr{}_HMM_MCK{}.csv\".format(d, order), index=False, header=False, sep=\" \")\n",
    "\n",
    "        test_string = pd.read_csv(\"data/Xte{}.csv\".format(d), index_col=0)\n",
    "        test_num = [\n",
    "            translate(dna_string)\n",
    "            for dna_string in test_string.values[:, 0]\n",
    "        ]\n",
    "        Xte = mc_features(test_num, A, B, pi, order)\n",
    "        pd.DataFrame(Xte).to_csv(\"data/Xte{}_HMM_MCK{}.csv\".format(d, order), index=False, header=False, sep=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:optim]",
   "language": "python",
   "name": "conda-env-optim-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
